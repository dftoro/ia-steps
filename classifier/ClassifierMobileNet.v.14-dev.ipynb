{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc2ca09f-25cd-4dee-a3e4-dfcc5798db4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.17.0\n",
      "keras: 3.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import logging\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('smote_process.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f'tensorflow: {tf.__version__}')\n",
    "print(f'keras: {tf.keras.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e4108ac-03e2-4863-af9b-1406c54a88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuración inicial\n",
    "LOCAL_IMAGE_PATH = './repo_dataset'\n",
    "TARGET_SIZE = (224, 224)\n",
    "TARGET_SIZE_CHANNEL = (224, 224, 3)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Columnas de clases\n",
    "LABEL_COLUMNS = ['direccion', 'fachada', 'envio', 'etiqueta', 'planilla']\n",
    "\n",
    "#cargar csv y dividir en dev set y test set\n",
    "#CSV_PATH = '.\\mobilnet-multi-label-dev-test-50.csv'\n",
    "CSV_PATH = './mobilnet-multi-label-train-60-planilla.csv'\n",
    "\n",
    "CSV_PATH_DEV = './mobilnet-multi-label-dev-50-planilla.csv'\n",
    "CSV_PATH_TEST = './mobilnet-multi-label-test-50-planilla.csv'\n",
    "\n",
    "CSV_TRAIN = CSV_PATH\n",
    "\n",
    "MODEL_NAME = 'mobilenetv3_classifier.v.14.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deb1ec5a-9c96-456e-9f6b-de972612b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar las imagenes\n",
    "def prepare_image(row, local_image_path, label_columns, target_size):\n",
    "    # Preparar las etiquetas\n",
    "    labels = row[label_columns].values.astype(int)\n",
    " \n",
    "    try:\n",
    "        # Cargar desde archivo local\n",
    "        img_path = os.path.join(local_image_path, row['filename'])\n",
    "        if os.path.exists(img_path):\n",
    "            image = Image.open(img_path)\n",
    "        elif pd.notna(row['urlAbsoluta']):    \n",
    "             urlAbsoluta = row['urlAbsoluta']\n",
    "             if 'http' in urlAbsoluta:\n",
    "                 # Descargar la imagen desde la URL\n",
    "                 response = requests.get(row['urlAbsoluta'], stream=True, timeout=10)\n",
    "                 if response.status_code == 200:\n",
    "                     image = Image.open(BytesIO(response.content))\n",
    "                     #guardar local para el siguiente ciclo de entrenamiento/prueba\n",
    "                     image.save(img_path)\n",
    "             elif os.path.exists(urlAbsoluta):\n",
    "                 image = Image.open(urlAbsoluta)\n",
    "             else:\n",
    "                 raise Exception(f'Error cargando {urlAbsoluta}, archivo no encontrado')\n",
    "    \n",
    "        # Convertir a RGB (en caso de que la imagen esté en otro formato, como RGBA)\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # Redimensionar la imagen\n",
    "        image = image.resize(target_size)  # Redimensionar a 224x224 para MobileNetV3\n",
    "        \n",
    "        # Convertir a un array de numpy y normalizar\n",
    "        image = np.array(image) / 255.0  # Normalizar\n",
    "        \n",
    "        return image, np.array(labels)\n",
    "    except BaseException as e:\n",
    "        print(f'Error en: {img_path}, Excepción: {str(e)}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "955a14bf-2e6f-4024-aff7-327d993c9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Augmentation para robustecer el entrenamiento\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal_and_vertical'),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2)\n",
    "])\n",
    "\n",
    "def build_model(num_classes):\n",
    "    # 1. Cargar el modelo base pre-entrenado (MobileNetV3Large) sin la capa de clasificación final\n",
    "    base_model = tf.keras.applications.MobileNetV3Large(\n",
    "        input_shape=TARGET_SIZE_CHANNEL,\n",
    "        include_preprocessing=False, # las imagnes de entrada estan normalizadas [0,1] y el modelo espera [0,255]\n",
    "        include_top=False,  # Excluimos la parte de clasificación original\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Construir la nueva arquitectura agregando una cabeza de clasificación para multi-label\n",
    "    inputs = tf.keras.Input(shape=TARGET_SIZE_CHANNEL)\n",
    "    # Aplicar data augmentation PRIMERO (en [0,1])\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # Luego normalizar a [-1,1]\n",
    "    x = layers.Rescaling(scale=2.0, offset=-1.0)(x)  # Mapea [0,1] a [-1,1]\n",
    "\n",
    "    # Pasar por la base pre-entrenada (no se necesita rescaling adicional)\n",
    "    x = base_model(x, training=False)  # training=False mantiene fijos los parámetros de BatchNorm\n",
    "    \n",
    "    # Utilizar GlobalAveragePooling2D para aplanar la salida del base model\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Agregar capa densa con regularización L2, BatchNormalization y Dropout\n",
    "    x = layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Capa de salida para multi-label con activación sigmoide\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e8f1484-9826-4d82-9859-03d6893917ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparado con 25226 imágenes sin SOMTE\n",
      "Distribución de clases sin SMOTE:\n",
      "direccion: 17.26% (4354/25226)\n",
      "fachada: 18.75% (4730/25226)\n",
      "envio: 52.93% (13353/25226)\n",
      "etiqueta: 37.87% (9553/25226)\n",
      "planilla: 17.49% (4412/25226)\n",
      "25226 [4354, 4730, 13353, 9553, 4412]\n",
      "frecuencia=[4354, 4730, 13353, 9553, 4412], alpha=[0.8274003012764608, 0.8124950447950527, 0.47066518671212243, 0.6213034171093317, 0.8251010861809245]\n"
     ]
    }
   ],
   "source": [
    "# calcular frecuencias de las clases del set de entrenamiento antes de smote\n",
    "def print_class_distribution_from_csv_no_SMOTE(csv_path, label_columns):\n",
    "    \"\"\"\n",
    "    Imprime la distribución de clases leyendo desde un archivo CSV\n",
    "    \n",
    "    Parámetros:\n",
    "    csv_path: str - Ruta al archivo CSV\n",
    "    label_columns: list - Lista de nombres de las columnas de etiquetas\n",
    "    \"\"\"\n",
    "    # Leer solo las columnas necesarias del CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df['filename'].str.startswith('synth_')==False]\n",
    "    total_samples = len(df)\n",
    "    frecuencias = [0] * len(label_columns)\n",
    "    \n",
    "    print(f\"Dataset preparado con {total_samples} imágenes sin SOMTE\")\n",
    "    print(f\"Distribución de clases sin SMOTE:\")\n",
    "    \n",
    "    for idx, col in enumerate(label_columns):\n",
    "        positive_samples = df[col].sum()\n",
    "        percentage = (positive_samples / total_samples) * 100\n",
    "        print(f\"{col}: {percentage:.2f}% ({int(positive_samples)}/{total_samples})\")\n",
    "        frecuencias[idx] = positive_samples\n",
    "    return total_samples, frecuencias\n",
    "\n",
    "total_samples, frecuencias = print_class_distribution_from_csv_no_SMOTE(CSV_TRAIN, LABEL_COLUMNS)\n",
    "print(total_samples, frecuencias)\n",
    "alpha = [n / total_samples for n in frecuencias]  \n",
    "alpha = [1 - n for n in alpha]  \n",
    "print(f'frecuencia={frecuencias}, alpha={alpha}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ca2f568-6ce9-4efd-83a7-b83702205995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', threshold=0.5, **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Aplicamos el umbral a las predicciones\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        tp = tf.reduce_sum(y_true * y_pred)\n",
    "        fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "        fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "        \n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "    \n",
    "    def result(self):\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.false_negatives.assign(0)\n",
    "\n",
    "\n",
    "class F1ScoreMacro(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, threshold=0.5, name='f1_macro', **kwargs):\n",
    "        super(F1ScoreMacro, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.threshold = threshold\n",
    "        self.f1_per_class = [F1Score(threshold=threshold) for _ in range(num_classes)]\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        for i in range(self.num_classes):\n",
    "            self.f1_per_class[i].update_state(y_true[:, i], y_pred[:, i], sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.reduce_mean([f1.result() for f1 in self.f1_per_class])\n",
    "\n",
    "    def reset_state(self):\n",
    "        for f1 in self.f1_per_class:\n",
    "            f1.reset_state()\n",
    "\n",
    "class F1ScoreMicro(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=0.5, name='f1_micro', **kwargs):\n",
    "        super(F1ScoreMicro, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        self.true_positives.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "        self.false_positives.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "        self.false_negatives.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.false_negatives.assign(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b600dc2-6f4e-46c6-97ca-4085f4612d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size, img_size, local_image_path, label_columns, shuffle=True):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.dataframe))\n",
    "        self.on_epoch_end()\n",
    "        self.local_image_path = local_image_path\n",
    "        self.label_columns = label_columns\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = min((index + 1) * self.batch_size, len(self.dataframe))\n",
    "        batch_indices = self.indices[start:end]\n",
    "        batch_data = self.dataframe.iloc[batch_indices]\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for _, row in batch_data.iterrows():\n",
    "            result = prepare_image(row, self.local_image_path, self.label_columns, self.img_size)\n",
    "            # Ya sabemos que prepare_image debería retornar datos válidos porque se filtró\n",
    "            if result is not None:\n",
    "                img, label = result\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print('Omitiendo imagen inesperadamente:', row['filename'])\n",
    "                continue\n",
    "        \n",
    "        X, y = np.array(images), np.array(labels)        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bea8ec67-c0b5-4837-97e6-4b287ce6212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldDataGenerator(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size=32, shuffle=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Usamos ceil para cubrir todos los ejemplos, incluso si el total no es múltiplo exacto de batch_size\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.file_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Índices del batch actual\n",
    "        batch_indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        labels_batch = []\n",
    "        for i in batch_indexes:\n",
    "            columnas = ['filename', 'urlAbsoluta', 'direccion', 'fachada', 'envio', 'etiqueta', 'planilla']\n",
    "            df = pd.DataFrame(columns=columnas)\n",
    "            new_row = {\n",
    "                'filename': self.file_paths[i],\n",
    "                'urlAbsoluta': '',\n",
    "                'direccion': self.labels[i][0],\n",
    "                'fachada': self.labels[i][1],\n",
    "                'envio': self.labels[i][2],\n",
    "                'etiqueta': self.labels[i][3],\n",
    "                'planilla': self.labels[i][4]\n",
    "            }\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            ultima_fila = df.loc[len(df) - 1]\n",
    "            result = prepare_image(ultima_fila, LOCAL_IMAGE_PATH, LABEL_COLUMNS, TARGET_SIZE)\n",
    "\n",
    "            if result is not None:\n",
    "                image, _ = result\n",
    "                images.append(image)\n",
    "                labels_batch.append(self.labels[i])\n",
    "            else: \n",
    "                continue\n",
    "        \n",
    "        # Convertir la lista de imágenes a un tensor (batch, 224, 224, 3)\n",
    "        X = tf.stack(images)\n",
    "        Y = tf.convert_to_tensor(labels_batch, dtype=tf.float32)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c489cb67-d0f8-413c-8bd1-e03db0b254b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de datos:\n",
      "Dataset de entrenamiento - Total: 61093, Reales: 25226, Sintéticos: 35867\n",
      "Dataset de validación: 8449 muestras\n",
      "Dataset de prueba: 8273 muestras\n",
      "loss...\n",
      "loss OK\n",
      "\n",
      "===== Fold 1 / 5 =====\n",
      "Fase 1: Entrenamiento con base congelada\n",
      "Error en: ./repo_dataset\\synth_planilla_7d1c2f2d.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_5f8f58bd.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_etiqueta_789d59dd.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_e620a366.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_16675b61.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_03933dea.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_e713fdbf.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_0266d1e3.jpg, Excepción: Error cargando , archivo no encontrado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en: ./repo_dataset\\synth_fachada_930305e2.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_e1e99bca.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_d4b7024b.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_etiqueta_097ee47d.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_24300cda.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_etiqueta_8878fa59.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_201a3cad.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_8d29e5e3.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_5c0080d8.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_e8ed1915.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_a98a4f4d.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_94d945df.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_8d1683ac.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_79aa597a.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_7714821b.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_6cd7c1f2.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_956d0b17.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_9932112b.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_52053881.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_2bd59dec.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_1ecb7544.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_040d578e.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_a452aadb.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_a6df9ab2.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_77e6552c.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_1b9f1505.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_1fc0ac3d.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_5e137ac7.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Epoch 1/5\n",
      "Error en: ./repo_dataset\\synth_direccion_bfad769f.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_b4c3f85f.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_7cfbfd2a.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_a3ef7724.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_3cd61c9e.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_cfda5d47.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_5aef91dd.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_ab30cc4e.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_b45ff068.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_d1eca03c.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_693efdde.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_5018a8e2.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_b1fa104b.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_fabc904c.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_ec555144.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_f0920ea6.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_493c8262.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_c3db33f3.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_ad1d69c5.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_ef0a2e5d.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_f9950fc5.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_534177a7.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_9b760f13.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_61c7ca1a.jpg, Excepción: Error cargando , archivo no encontrado\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 85\u001b[0m\n\u001b[0;32m     78\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     79\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m),\n\u001b[0;32m     80\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryFocalCrossentropy(gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m, alpha\u001b[38;5;241m=\u001b[39malpha),\n\u001b[0;32m     81\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[f1_macro, f1_micro]\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFase 1: Entrenamiento con base congelada\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m history1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# --- Fase 2: Fine-Tuning ---\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Descongelar las últimas 20 capas del modelo base\u001b[39;00m\n\u001b[0;32m     94\u001b[0m base_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMobileNetV3Large\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Índice de la capa MobileNetV3\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    915\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[0;32m    916\u001b[0m           bound_args\n\u001b[0;32m    917\u001b[0m       )\n\u001b[0;32m    918\u001b[0m   )\n\u001b[1;32m--> 919\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    920\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[0;32m    925\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classifier_17\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en: ./repo_dataset\\synth_direccion_a5af0d0e.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_7b755430.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_0ed61ca4.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_direccion_c2cb0783.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_b3882aa4.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_2f996d46.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_7b81cdbe.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_fachada_d41c72ad.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_40dfb647.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_8d63f65c.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_f5124a78.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_864aab8d.jpg, Excepción: Error cargando , archivo no encontrado\n",
      "Error en: ./repo_dataset\\synth_planilla_32c5c9ce.jpg, Excepción: Error cargando , archivo no encontrado\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Dataset de entrenamiento (contiene datos sintéticos)\n",
    "csv_path_train = CSV_TRAIN\n",
    "df_train = pd.read_csv(csv_path_train)\n",
    "\n",
    "# Dataset de validación (sin datos sintéticos)\n",
    "csv_path_dev = CSV_PATH_DEV\n",
    "df_dev = pd.read_csv(csv_path_dev)\n",
    "\n",
    "# Dataset de prueba (sin datos sintéticos)\n",
    "csv_path_test = CSV_PATH_TEST\n",
    "df_test = pd.read_csv(csv_path_test)\n",
    "\n",
    "# Filtrar datos sintéticos del conjunto de entrenamiento\n",
    "# Asumiendo que podemos identificar datos sintéticos en el nombre del archivo\n",
    "# Adaptarlo según el método que usas para identificar datos sintéticos\n",
    "df_train_real = df_train[df_train['filename'].str.startswith('synth_')==False]\n",
    "\n",
    "print('Estadísticas de datos:')\n",
    "print(f'Dataset de entrenamiento - Total: {len(df_train)}, Reales: {len(df_train_real)}, Sintéticos: {len(df_train) - len(df_train_real)}')\n",
    "print(f'Dataset de validación: {len(df_dev)} muestras')\n",
    "print(f'Dataset de prueba: {len(df_test)} muestras')\n",
    "\n",
    "# Para el K-fold, solo usaremos los datos reales del conjunto de entrenamiento\n",
    "file_paths_train = df_train['filename'].values\n",
    "labels_train = df_train[LABEL_COLUMNS].values.astype(np.float32)\n",
    "\n",
    "dev_file_paths = df_dev['filename'].values\n",
    "dev_labels = df_dev[LABEL_COLUMNS].values.astype(np.float32)\n",
    "\n",
    "# Parámetros\n",
    "k_splits = 5\n",
    "batch_size = BATCH_SIZE\n",
    "initial_epochs = 5\n",
    "finetune_epochs = 5   # Fase 2: fine-tuning (descongelar últimas 20 capas)\n",
    "input_shape = TARGET_SIZE_CHANNEL\n",
    "num_classes = len(LABEL_COLUMNS)\n",
    "\n",
    "print('loss...')\n",
    "loss_fn = tf.keras.losses.BinaryFocalCrossentropy(gamma=2.0, alpha=alpha)\n",
    "print('loss OK')\n",
    "\n",
    "# Optimizador con learning rate adaptativo\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "num_classes = len(LABEL_COLUMNS)\n",
    "# F1-score macro promedia la F1 de cada clase.\n",
    "f1_macro = F1ScoreMacro(num_classes=num_classes, threshold=0.5)\n",
    "\n",
    "# F1-score micro calcula la F1 global (acumulando TP, FP, FN de todas las clases).\n",
    "f1_micro = F1ScoreMicro(threshold=0.5)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=k_splits, shuffle=True, random_state=42)\n",
    "fold_no = 1\n",
    "best_val_loss = np.inf  # Para guardar el mejor modelo\n",
    "final_model = None      # Para almacenar el modelo final\n",
    "histories = []          # Para almacenar history de cada fold (opcional)\n",
    "\n",
    "for train_idx, val_idx in kf.split(file_paths_train):\n",
    "    print(f'\\n===== Fold {fold_no} / {k_splits} =====')\n",
    "    train_paths, train_labels = file_paths_train[train_idx], labels_train[train_idx]\n",
    "    \n",
    "    # Para validación, se utiliza todo el CSV de validación (solo datos reales)\n",
    "    val_paths, val_labels = dev_file_paths, dev_labels\n",
    "    \n",
    "    # Crear generadores\n",
    "    train_gen = KFoldDataGenerator(train_paths, train_labels, batch_size=batch_size, shuffle=True)\n",
    "    val_gen = KFoldDataGenerator(val_paths, val_labels, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    # --- Fase 1: Entrenamiento con la base congelada ---\n",
    "    model = build_model(num_classes=len(LABEL_COLUMNS))\n",
    "    model.compile(\n",
    "        optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=tf.keras.losses.BinaryFocalCrossentropy(gamma=2.0, alpha=alpha),\n",
    "        metrics=[f1_macro, f1_micro]\n",
    "    )\n",
    "    \n",
    "    print('Fase 1: Entrenamiento con base congelada')\n",
    "    history1 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=initial_epochs,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # --- Fase 2: Fine-Tuning ---\n",
    "    # Descongelar las últimas 20 capas del modelo base\n",
    "    base_model = model.get_layer('MobileNetV3Large') # Índice de la capa MobileNetV3\n",
    "    # En algunos casos, es mejor usar el nombre. Por ejemplo:\n",
    "    # base_model = model.get_layer('mobilenetv3large')\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-20]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-20:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "        loss=tf.keras.losses.BinaryFocalCrossentropy(gamma=2.0, alpha=alpha),\n",
    "        metrics=[f1_macro, f1_micro]\n",
    "    )\n",
    "    \n",
    "    print('Fase 2: Fine-tuning descongelando las últimas 20 capas')\n",
    "    history2 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=finetune_epochs,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Combinar histories (opcional, para graficar)\n",
    "    history_combined = {}\n",
    "    for key in history1.history.keys():\n",
    "        history_combined[key] = history1.history[key] + history2.history[key]\n",
    "    histories.append(history_combined)\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de validación\n",
    "    scores = model.evaluate(val_gen, verbose=0)\n",
    "    print(f\"Resultados fold {fold_no}: {model.metrics_names} = {scores}\")\n",
    "    \n",
    "    # Guardar el modelo si obtuvo menor pérdida de validación\n",
    "    val_loss = scores[model.metrics_names.index('loss')]\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        final_model = model  # Se guarda el modelo con la mejor pérdida de validación\n",
    "        model.save(MODEL_NAME)\n",
    "        print(f\"Nuevo mejor modelo guardado (fold {fold_no})\")\n",
    "    \n",
    "    # Graficar la evolución de las métricas de este fold\n",
    "    epochs_total = initial_epochs + finetune_epochs\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    # Pérdida\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(1, epochs_total+1), history_combined['loss'], label='Pérdida Entrenamiento')\n",
    "    plt.plot(range(1, epochs_total+1), history_combined['val_loss'], label='Pérdida Validación')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.title('Pérdida')\n",
    "    plt.legend()\n",
    "    \n",
    "    # F1 Macro\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(1, epochs_total+1), history_combined['f1_macro'], label='F1 Macro Entrenamiento')\n",
    "    plt.plot(range(1, epochs_total+1), history_combined['val_f1_macro'], label='F1 Macro Validación')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('F1 Macro')\n",
    "    plt.title('F1 Macro')\n",
    "    plt.legend()\n",
    "    \n",
    "    # F1 Micro\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(1, epochs_total+1), history_combined['f1_micro'], label='F1 Micro Entrenamiento')\n",
    "    plt.plot(range(1, epochs_total+1), history_combined['val_f1_micro'], label='F1 Micro Validación')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('F1 Micro')\n",
    "    plt.title('F1 Micro')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.suptitle(f\"Resultados del Fold {fold_no}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    fold_no += 1\n",
    "\n",
    "# Mostrar resultados promedio (por ejemplo, promedio de la pérdida de validación)\n",
    "# (Aquí se puede agregar cálculo de promedios si se almacenan los scores de cada fold)\n",
    "print(f'\\nProceso de K-Fold completado. El mejor modelo se guardó como {MODEL_NAME}.')\n",
    "\n",
    "# PASO FINAL: Evaluar el mejor modelo en el conjunto de test real\n",
    "# Preparar el generador para el conjunto de test\n",
    "csv_path_test = CSV_PATH_TEST \n",
    "df_test = pd.read_csv(csv_path_test)\n",
    "test_paths = df_test['filename'].values\n",
    "test_labels = df_test[LABEL_COLUMNS].values.astype(np.float32)\n",
    "test_gen = KFoldDataGenerator(test_paths, test_labels, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de test\n",
    "print('\\n===== Evaluación final en el conjunto de TEST =====')\n",
    "test_scores = final_model.evaluate(test_gen, verbose=1)\n",
    "print(f'Rendimiento en test: {final_model.metrics_names} = {test_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1422e50-c3fe-4fc2-b4bf-638e49e55129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "# Supongamos que tienes el conjunto de validación como un data generator\n",
    "# y_true_total y y_pred_total se obtienen acumulando las etiquetas verdaderas y las predichas.\n",
    "\n",
    "y_true_total = []\n",
    "y_pred_total = []\n",
    "\n",
    "val_df = pd.read_csv(CSV_PATH_TEST)\n",
    "val_gen = CustomDataGenerator(val_df, BATCH_SIZE, TARGET_SIZE, LOCAL_IMAGE_PATH, label_columns=LABEL_COLUMNS, shuffle=False)\n",
    "model = load_model('mobilenetv3_classifier.v.13.keras', \n",
    "                   custom_objects={\n",
    "                       'F1ScoreMacro': lambda **kwargs: F1ScoreMacro(num_classes=len(LABEL_COLUMNS), threshold=0.5, **kwargs),\n",
    "                       'F1ScoreMicro': lambda **kwargs: F1ScoreMicro(threshold=0.5, **kwargs)\n",
    "    })\n",
    "model.summary()\n",
    "\n",
    "for i in range(len(val_gen)):\n",
    "    X_batch, y_batch = val_gen[i]\n",
    "    preds = model.predict(X_batch)\n",
    "    y_true_total.append(y_batch)\n",
    "    y_pred_total.append(preds)\n",
    "    \n",
    "    \n",
    "print('generando...')\n",
    "# Convertir a arrays\n",
    "y_true_total = np.vstack(y_true_total)\n",
    "y_pred_total = np.vstack(y_pred_total)\n",
    "\n",
    "# Aplicar umbral para obtener predicciones binarias\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred_total > threshold).astype(int)\n",
    "\n",
    "# Ahora, para cada clase, calculamos y graficamos la matriz de confusión\n",
    "num_classes = y_true_total.shape[1]\n",
    "\n",
    "for i in range(num_classes):\n",
    "    cm = confusion_matrix(y_true_total[:, i], y_pred_binary[:, i])\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Matriz de Confusión - {LABEL_COLUMNS[i]}')\n",
    "    plt.xlabel('Predicho')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a62ab-26f2-4669-85a3-36a869fc51f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar el modelo (agregando custom_objects si usas métricas personalizadas)\n",
    "\n",
    "'''\n",
    "model = tf.keras.models.load_model('mobilenetv3_classifier.v.13-ok.keras',\n",
    "    custom_objects={\n",
    "        'F1ScoreMacro': lambda **kwargs: F1ScoreMacro(num_classes=4, threshold=0.5, **kwargs),\n",
    "        'F1ScoreMicro': lambda **kwargs: F1ScoreMicro(threshold=0.5, **kwargs)\n",
    "    })\n",
    "\n",
    "'''\n",
    "model = tf.keras.models.load_model('mobilenetv3_classifier.v.13.keras',\n",
    "    custom_objects={\n",
    "        'F1ScoreMacro': lambda **kwargs: F1ScoreMacro(num_classes=4, threshold=0.5, **kwargs),\n",
    "        'F1ScoreMicro': lambda **kwargs: F1ScoreMicro(threshold=0.5, **kwargs)\n",
    "    })\n",
    "\n",
    "\n",
    "# 2. Función para cargar y preprocesar la imagen\n",
    "# cargar las imagenes\n",
    "def prepare_image(row, local_image_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        # Cargar desde archivo local\n",
    "        img_path = os.path.join(local_image_path, row['filename'])\n",
    "        print(f\"img_path: {img_path}\")\n",
    "        if os.path.exists(img_path):\n",
    "            image = Image.open(img_path)\n",
    "        elif pd.notna(row['urlAbsoluta']):    \n",
    "             urlAbsoluta = row['urlAbsoluta']\n",
    "             if 'http' in urlAbsoluta:\n",
    "                 print(f\"urlAbsoluta: {urlAbsoluta}\")\n",
    "                 # Descargar la imagen desde la URL\n",
    "                 response = requests.get(row['urlAbsoluta'], stream=True, timeout=10)\n",
    "                 if response.status_code == 200:\n",
    "                     image = Image.open(BytesIO(response.content))\n",
    "                     #guardar local para el siguiente ciclo de entrenamiento/prueba\n",
    "                     image.save(img_path)\n",
    "             elif os.path.exists(urlAbsoluta):\n",
    "                 image = Image.open(urlAbsoluta)\n",
    "             else:\n",
    "                 raise Exception(f'Error cargando {urlAbsoluta}, archivo no encontrado')\n",
    "    \n",
    "        # Convertir a RGB (en caso de que la imagen esté en otro formato, como RGBA)\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # Redimensionar la imagen\n",
    "        image = image.resize(target_size)  # Redimensionar a 224x224 para MobileNetV3\n",
    "        \n",
    "        # Convertir a un array de numpy y normalizar\n",
    "        image = np.array(image) / 255.0  # Normalizar\n",
    "\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        return image\n",
    "    except BaseException as e:\n",
    "        print(f'Error en: {img_path}, Excepción: {str(e)}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def visualize_images(images, labels, title, num_images=5):\n",
    "    \"\"\"\n",
    "    Muestra un conjunto de imágenes con sus etiquetas asociadas.\n",
    "    \n",
    "    Args:\n",
    "        images (np.array): Arreglo de imágenes (formato HWC, RGB).\n",
    "        labels (np.array): Etiquetas asociadas a las imágenes.\n",
    "        title (str): Título de la visualización.\n",
    "        num_images (int): Número de imágenes a mostrar.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(min(num_images, len(images))):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        img = images[i]\n",
    "        \n",
    "        # Asegurar que la imagen esté en el rango [0, 255]\n",
    "        if img.max() <= 1.0:\n",
    "            img = img * 255.0\n",
    "        img = img.astype(\"uint8\")\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Etiqueta: {labels[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# 3. Cargar una imagen real (ruta a la imagen)\n",
    "image_path = './repo_validation'  # Cambia a la ruta de la imagen que quieres probar\n",
    "csv_validaton = './dataset_validacion_manual.csv'\n",
    "\n",
    "df = pd.read_csv(csv_validaton)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    print(f\"-->> Row {i}: {df.iloc[i]}\")\n",
    "    img_array = prepare_image(df.iloc[i], local_image_path=image_path)\n",
    "\n",
    "    if img_array is None:\n",
    "        continue\n",
    "\n",
    "    # 4. Realizar la predicción\n",
    "    predictions = model.predict(img_array)\n",
    "    print(str(i), ': Predicciones (probabilidades):', predictions)\n",
    "    \n",
    "    # 5. Aplicar un umbral para obtener etiquetas binarias (para multi-etiqueta)\n",
    "    #threshold = 0.57  # dev set\n",
    "    threshold = 0.5 # train set\n",
    "    pred_labels = (predictions > threshold).astype(int)\n",
    "\n",
    "    images = [img_array[0,...]];\n",
    "    print(LABEL_COLUMNS)\n",
    "    visualize_images(images, pred_labels, 'Predicciones', num_images=1)\n",
    "    \n",
    "    print('Etiquetas predichas:', pred_labels)\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "    if(i > 50):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da738cd3-95e5-48d0-bdbb-1e20bfa687b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
