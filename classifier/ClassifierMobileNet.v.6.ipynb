{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1f6942-214e-47dd-9ad7-adebd8c9ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900ea8cd-35c7-48f7-b66e-1e4a915d906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length dataset 28246, length saamples 28246\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuración inicial\n",
    "LOCAL_IMAGE_PATH = './repo_dataset'\n",
    "TARGET_SIZE = (224, 224)\n",
    "TARGET_SIZE_CHANNEL = (224, 224, 3)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#cargar csv y dividir en dev set y test set\n",
    "# Load the dataset into a DataFrame\n",
    "#CSV_PATH = '.\\mobilnet-multi-label-solo-local.csv'\n",
    "CSV_PATH = '.\\mobilnet-multi-label.csv'\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Columnas de clases\n",
    "LABEL_COLUMNS = ['direccion', 'fachada', 'envio', 'etiqueta']\n",
    "\n",
    "# Shuffle the dataset\n",
    "# 20% dev set \n",
    "#20% test set\n",
    "sample_df = df.sample(n=int(len(df)*1))\n",
    "print(f'Length dataset {len(df)}, length saamples {len(sample_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42327be-33c2-4d77-8a58-8a31674ccf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar las imagenes\n",
    "def prepare_image(row, local_image_path, label_columns, target_size):\n",
    "    # Preparar las etiquetas\n",
    "    labels = row[label_columns].values.astype(int)\n",
    "    \n",
    "    # Cargar desde archivo local\n",
    "    img_path = os.path.join(local_image_path, row['filename'])\n",
    "    if os.path.exists(img_path):\n",
    "        image = Image.open(img_path)\n",
    "    elif pd.notna(row['urlAbsoluta']):    \n",
    "         # Descargar la imagen desde la URL\n",
    "         response = requests.get(row['urlAbsoluta'], stream=True, timeout=10)\n",
    "         if response.status_code == 200:\n",
    "             image = Image.open(BytesIO(response.content))\n",
    "             #guardar local para el siguiente ciclo de entrenamiento/prueba\n",
    "             image.save(img_path)\n",
    "\n",
    "    # Convertir a RGB (en caso de que la imagen esté en otro formato, como RGBA)\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    # Redimensionar la imagen\n",
    "    image = image.resize(target_size)  # Redimensionar a 224x224 para MobileNetV3\n",
    "    \n",
    "    # Convertir a un array de numpy y normalizar\n",
    "    image = np.array(image) / 255.0  # Normalizar\n",
    "    \n",
    "    return image, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676b8a7b-c88b-4442-b279-439c013a3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_distribution(X, y, label_columns):\n",
    "    print(f\"Dataset preparado con {len(X)} imágenes\")\n",
    "    print(f\"Distribución de clases:\")\n",
    "    for i, col in enumerate(label_columns):\n",
    "        positive_samples = np.sum(y[:, i])\n",
    "        percentage = (positive_samples / len(y)) * 100\n",
    "        print(f\"{col}: {percentage:.2f}% ({int(positive_samples)}/{len(y)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2abd4e-47a4-4212-9f76-bf7f617dc8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, local_image_path, label_columns, target_size, max_workers=4):\n",
    "    labels = []\n",
    "    images = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Procesar cada fila del DataFrame\n",
    "        futures = [executor.submit(prepare_image, row, local_image_path, label_columns, target_size) \n",
    "                   for _, row in df.iterrows()]\n",
    "          \n",
    "        # Recolectar resultados con barra de progreso\n",
    "        for future in tqdm(futures, total=len(df)):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                img_array, img_labels = result\n",
    "                images.append(img_array)\n",
    "                labels.append(img_labels)\n",
    "\n",
    "    # Convertir a arrays numpy\n",
    "    X = np.array(images)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcdb785-d1ea-4a59-88bd-2e188c2a2957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▉                                                      | 8152/28246 [00:47<02:28, 134.92it/s]"
     ]
    }
   ],
   "source": [
    "print('prepare_dataset...')\n",
    "\n",
    "X,y = prepare_dataset(sample_df, LOCAL_IMAGE_PATH, LABEL_COLUMNS, TARGET_SIZE)        \n",
    "\n",
    "print('prepare_dataset OK')\n",
    "\n",
    "print_class_distribution(X, y, LABEL_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e2182-7d2e-4863-be77-30fd96c37396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en dev=50% y test=50%\n",
    "def split_dataset(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(\n",
    "            X, y,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y.sum(axis=1)  # Estratificar por número total de etiquetas\n",
    "        )\n",
    "\n",
    "\n",
    "print('split_dataset...')\n",
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = split_dataset(X, y, test_size=0.2)\n",
    "\n",
    "print(f'X_train: {len(X_train)}, y_train: {len(y_train)}, X_test: {len(X_test)}, y_test {len(y_test)}')\n",
    "\n",
    "print('split_dataset. OK')\n",
    "\n",
    "print_class_distribution(X_train, y_train, LABEL_COLUMNS)\n",
    "\n",
    "print('liberarndo X y y')\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434bf7df-e309-4a74-9f37-60ea62ebcdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelSMOTE:\n",
    "    def __init__(self, k_neighbors=5, target_samples=500, random_state=None):\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.target_samples = target_samples  # Número objetivo de muestras por clase\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _reshape_for_knn(self, X):\n",
    "        \"\"\"Reshape the input data for KNN if necessary.\"\"\"\n",
    "        original_shape = X.shape\n",
    "        if len(original_shape) > 2:\n",
    "            # Aplanar todas las dimensiones excepto la primera (muestras)\n",
    "            n_samples = original_shape[0]\n",
    "            X_reshaped = X.reshape(n_samples, -1)\n",
    "            return X_reshaped, original_shape\n",
    "        return X, original_shape\n",
    "\n",
    "    def _restore_shape(self, X, original_shape):\n",
    "        \"\"\"Restaura la forma original de los datos.\"\"\"\n",
    "        if len(original_shape) > 2:\n",
    "            return X.reshape((-1,) + original_shape[1:])\n",
    "        return X\n",
    "\n",
    "    def _balance_label(self, X, y, label_idx):\n",
    "        # Indices de instancias con la etiqueta activa\n",
    "        idx = np.where(y[:, label_idx] == 1)[0]\n",
    "        X_label = X[idx]\n",
    "        y_label = y[idx]\n",
    "        \n",
    "        # Si ya hay suficientes muestras, no hacer nada\n",
    "        if len(X_label) >= self.target_samples:\n",
    "            return X_label, y_label\n",
    "\n",
    "         # Reshape data for KNN\n",
    "        X_reshaped, original_shape = self._reshape_for_knn(X_label)\n",
    "        \n",
    "        # Calcular cuántas muestras sintéticas se necesitan\n",
    "        n_needed = self.target_samples - len(X_label)\n",
    "        \n",
    "        # Encontrar vecinos más cercanos\n",
    "        knn = NearestNeighbors(n_neighbors=self.k_neighbors)\n",
    "        knn.fit(X_reshaped)\n",
    "        distances, indices = knn.kneighbors(X_reshaped)\n",
    "        \n",
    "        # Generar muestras sintéticas\n",
    "        synthetic_X = []\n",
    "        synthetic_y = []\n",
    "        \n",
    "        for _ in range(n_needed):\n",
    "            i = np.random.randint(0, len(X_label))\n",
    "            neighbor_idx = np.random.choice(indices[i])\n",
    "            gap = np.random.uniform(0, 1)\n",
    "\n",
    "            # Generar muestra sintética en el espacio aplanado\n",
    "            synthetic = X_reshaped[i] + gap * (X_reshaped[neighbor_idx] - X_reshaped[i])\n",
    "            synthetic_X.append(synthetic)\n",
    "            synthetic_y.append(y_label[i])\n",
    "\n",
    "         # Convertir a arrays y restaurar la forma original\n",
    "        synthetic_X = np.array(synthetic_X)\n",
    "        synthetic_X = self._restore_shape(synthetic_X, original_shape)\n",
    "            \n",
    "        return np.vstack([X_label, synthetic_X]), np.vstack([y_label, synthetic_y])\n",
    "    \n",
    "    def fit_resample(self, X, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        X_balanced, y_balanced = X.copy(), y.copy()\n",
    "        \n",
    "        for label_idx in range(y.shape[1]):\n",
    "            # Balancear cada etiqueta individualmente\n",
    "            X_bal, y_bal = self._balance_label(X_balanced, y_balanced, label_idx)\n",
    "\n",
    "            # Combinar con los datos existentes\n",
    "            X_balanced = np.vstack([X_balanced, X_bal])\n",
    "            y_balanced = np.vstack([y_balanced, y_bal])\n",
    "\n",
    "        # Eliminar duplicados\n",
    "        unique_indices = np.unique(X_balanced.reshape(X_balanced.shape[0], -1), axis=0, return_index=True)[1]\n",
    "        X_balanced = X_balanced[unique_indices]\n",
    "        y_balanced = y_balanced[unique_indices]\n",
    "        return X_balanced, y_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743ea86-6c5a-4e0a-bd5b-292508b1a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cargar modelo base (MobileNetV3 Large)\n",
    "# Aplicar SMOTE adaptado\n",
    "print('MultiLabelSMOTE...')\n",
    "mlsmote = MultiLabelSMOTE(target_samples=1000, k_neighbors=3, random_state=42)\n",
    "X_bal, y_bal = mlsmote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f'X_bal: {len(X_bal)}, y_bal: {len(y_bal)}')\n",
    "\n",
    "# Verificar balanceo\n",
    "print(\"Conteo original por clase:\", y_train.sum(axis=0))\n",
    "print(\"Conteo balanceado por clase:\", y_bal.sum(axis=0))\n",
    "\n",
    "print_class_distribution(X_bal, y_bal, LABEL_COLUMNS)\n",
    "print('MultiLabelSMOTE OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b16a89-de6a-4978-9937-1c845d00ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calcular pesos de clases adaptativos\n",
    "def calculate_class_weights(labels, alpha=0.7, smooth=1e-6):\n",
    "    class_counts = np.sum(labels, axis=0) + smooth\n",
    "    weights = (1 / class_counts) ** alpha  # Mayor énfasis en clases minoritarias\n",
    "    return weights / np.max(weights)  # Normalización a [0, 1]\n",
    "\n",
    "# 2. Data Augmentation Adaptativa\n",
    "class AdaptiveAugmenter(layers.Layer):\n",
    "    def __init__(self, class_weights, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.class_weights = tf.constant(class_weights, dtype=tf.float32)\n",
    "        self.rotation = layers.RandomRotation(factor=0.15, fill_mode='reflect')\n",
    "        self.zoom = layers.RandomZoom(height_factor=0.1, width_factor=0.1, fill_mode='reflect')\n",
    "        self.contrast = layers.RandomContrast(0.08)\n",
    "        self.clip = layers.Lambda(lambda x: tf.clip_by_value(x, 0.0, 1.0))\n",
    "\n",
    "    def get_sample_weight(self, label):\n",
    "        active_weights = tf.boolean_mask(self.class_weights, tf.cast(label, tf.bool))\n",
    "        max_weight = tf.reduce_max(active_weights) if tf.size(active_weights) > 0 else 0.0\n",
    "        mean_weight = tf.reduce_mean(active_weights) if tf.size(active_weights) > 0 else 0.0\n",
    "        return tf.sqrt(max_weight * mean_weight)\n",
    "\n",
    "    def adaptive_brightness(self, image, weight):\n",
    "        # Calcular delta basado en la intensidad y brillo actual\n",
    "        current_brightness = tf.reduce_mean(image)\n",
    "        # Calcular límites con conversión explícita\n",
    "        max_delta = tf.cast(\n",
    "            tf.minimum(0.1 * weight, 1.0 - current_brightness),\n",
    "            tf.float32\n",
    "        )\n",
    "        min_delta = tf.cast(\n",
    "            tf.maximum(-0.1 * weight, -current_brightness),\n",
    "            tf.float32\n",
    "        )\n",
    "        \n",
    "        # Generar delta con tipos consistentes\n",
    "        delta = tf.random.uniform(\n",
    "            shape=[],\n",
    "            minval=min_delta,\n",
    "            maxval=max_delta,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        return self.clip(image + delta)\n",
    "\n",
    "    def adaptive_augment(self, image, weight):\n",
    "        intensity = tf.minimum(1.0, weight ** 2)\n",
    "        if tf.random.uniform([]) < 0.3 * intensity:\n",
    "            image = self.rotation(image)\n",
    "        if tf.random.uniform([]) < 0.3 * intensity:\n",
    "            image = self.zoom(image)\n",
    "        if tf.random.uniform([]) < 0.3 * intensity:\n",
    "            image = self.adaptive_brightness(image, weight)\n",
    "        if tf.random.uniform([]) < 0.3 * intensity:\n",
    "            image = self.contrast(image)\n",
    "        return tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    def call(self, image, label):\n",
    "        weight = self.get_sample_weight(label)\n",
    "        prob_aug = 0.9 * (1 - tf.exp(-3 * weight))\n",
    "        return tf.cond(tf.random.uniform([]) < prob_aug, lambda: self.adaptive_augment(image, weight), lambda: image), label\n",
    "\n",
    "# 3. Generación del dataset balanceado\n",
    "def create_balanced_dataset(images, labels, class_weights, batch_size=32):\n",
    "    sample_weights = np.max(labels * class_weights, axis=1)  # Ponderar ejemplos\n",
    "    repeat_factors = np.ceil(sample_weights * 2).astype(int)  # Más repeticiones a clases raras\n",
    "    \n",
    "    images_augmented, labels_augmented = [], []\n",
    "    for img, lbl, repeat in zip(images, labels, repeat_factors):\n",
    "        for _ in range(repeat):\n",
    "            images_augmented.append(img)\n",
    "            labels_augmented.append(lbl)\n",
    "    \n",
    "    images_augmented = np.array(images_augmented)\n",
    "    labels_augmented = np.array(labels_augmented)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((tf.cast(images_augmented, tf.float32), labels_augmented))\n",
    "    augmenter = AdaptiveAugmenter(class_weights)\n",
    "    dataset = dataset.map(lambda x, y: augmenter(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(10 * batch_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# 4. Visualización de ejemplos aumentados\n",
    "def visualize_augmented_images(dataset, class_names, num_samples=9):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(num_samples):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            img = np.clip(images[i].numpy(), 0, 1)\n",
    "            plt.imshow(img)\n",
    "            title = ', '.join([class_names[j] for j in np.where(labels[i])[0]])\n",
    "            plt.title(title, fontsize=8)\n",
    "            plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('Augmentation...')\n",
    "# Ejemplo de uso\n",
    "class_weights = calculate_class_weights(y_bal, alpha=0.7)\n",
    "train_dataset = create_balanced_dataset(X_bal, y_bal, class_weights, batch_size=BATCH_SIZE)\n",
    "visualize_augmented_images(train_dataset, class_names=LABEL_COLUMNS)\n",
    "print('Augmentation OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de1fd7-3726-4914-8961-af9d6c6f26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Augmentation  estadística')\n",
    "# Imprimir estadísticas detalladas\n",
    "original_counts = np.sum(y_bal, axis=0)\n",
    "original_percent = original_counts / len(y_bal)\n",
    "augmented_counts = np.zeros_like(original_counts) if y_bal is not None else np.zeros(len(LABEL_COLUMNS))\n",
    "total_samples = 0\n",
    "\n",
    "# Procesar batches del dataset aumentado\n",
    "for i, (_, labels) in enumerate(train_dataset.take(BATCH_SIZE)):\n",
    "    batch_counts = tf.reduce_sum(labels, axis=0).numpy()\n",
    "    augmented_counts += batch_counts\n",
    "    total_samples += labels.shape[0]\n",
    "    \n",
    "augmented_percent = augmented_counts / total_samples if total_samples > 0 else np.zeros_like(augmented_counts)\n",
    "\n",
    "print(\"\\nEstadísticas Comparativas:\")\n",
    "print(f\"{'Clase':<15} | {'Original':<10} | {'Aumentado':<10} | {'Diferencia'}\")\n",
    "print(\"-\" * 50)\n",
    "for i, name in enumerate(LABEL_COLUMNS):\n",
    "    diff = augmented_percent[i] - original_percent[i]\n",
    "    print(f\"{name:<15} | {original_percent[i]:<10.1%} | {augmented_percent[i]:<10.1%} | {diff:+.1%}\")\n",
    "\n",
    "\n",
    "\n",
    "def mostrar_estadisticas_aumentacion(dataset, class_names, num_batches=None):\n",
    "    # Inicializar contadores\n",
    "    class_counts = np.zeros(len(class_names))\n",
    "    total_images = 0\n",
    "    \n",
    "    # Procesar el dataset\n",
    "    for i, (images, labels) in enumerate(dataset):\n",
    "        # Convertir etiquetas a numpy y actualizar contadores\n",
    "        batch_labels = labels.numpy()\n",
    "        class_counts += np.sum(batch_labels, axis=0)\n",
    "        total_images += batch_labels.shape[0]\n",
    "    \n",
    "    # Calcular porcentajes\n",
    "    print(f\"\\nCantidad total de imágenes: {total_images}\")\n",
    "    print(\"Distribución de clases:\")\n",
    "    for name, count in zip(class_names, class_counts):\n",
    "        porcentaje = (count / total_images) * 100\n",
    "        print(f\"{name}: {porcentaje:.2f}% ({int(count)}/{total_images})\")\n",
    "\n",
    "print('mostrar_estadisticas_aumentacion...')\n",
    "mostrar_estadisticas_aumentacion(train_dataset, class_names=LABEL_COLUMNS)\n",
    "print('mostrar_estadisticas_aumentacion OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cced74d-a137-43ba-a4b7-142e33cf1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_statistics(dataset, class_names, num_batches=100):\n",
    "    # Inicializar contador para cada clase\n",
    "    class_counts = np.zeros(len(class_names), dtype=int)\n",
    "    total_samples = 0\n",
    "\n",
    "    # Iterar sobre algunos batches del dataset\n",
    "    for images, labels in dataset.take(num_batches):\n",
    "        labels_np = labels.numpy()\n",
    "        class_counts += np.sum(labels_np, axis=0).astype(int)\n",
    "        total_samples += labels_np.shape[0]\n",
    "\n",
    "    print(f\"Estadísticas de clases acumuladas en {num_batches} batches:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        # Se asume que cada muestra se cuenta una vez, incluso si es multi-label\n",
    "        percentage = (class_counts[i] / total_samples) * 100 if total_samples > 0 else 0\n",
    "        print(f\"  {class_name}: {class_counts[i]} ejemplos, {percentage:.2f}% de los ejemplos\")\n",
    "        \n",
    "print(\"print_class_statistics...\")\n",
    "print_class_statistics(train_dataset, LABEL_COLUMNS, num_batches=50)\n",
    "print(\"print_class_statistics OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c5f8a-bfb2-4c14-a6c3-1a72c63e8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_statistics_full(dataset, class_names):\n",
    "    \"\"\"\n",
    "    Imprime la cantidad total y el porcentaje de ejemplos por clase recorriendo todo el dataset.\n",
    "    Se asume que el dataset es finito.\n",
    "    \"\"\"\n",
    "    class_counts = np.zeros(len(class_names), dtype=int)\n",
    "    total_samples = 0\n",
    "\n",
    "    # Recorrer el dataset completo\n",
    "    for images, labels in dataset:\n",
    "        labels_np = labels.numpy()\n",
    "        class_counts += np.sum(labels_np, axis=0).astype(int)\n",
    "        total_samples += labels_np.shape[0]\n",
    "\n",
    "    print(\"Estadísticas de clases en el dataset completo:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        percentage = (class_counts[i] / total_samples) * 100 if total_samples > 0 else 0\n",
    "        print(f\"  {class_name}: {class_counts[i]} ejemplos, {percentage:.2f}% de los ejemplos\")\n",
    "\n",
    "print(\"print_class_statistics_full...\")\n",
    "print_class_statistics_full(train_dataset, LABEL_COLUMNS)\n",
    "print(\"print_class_statistics_full OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e3c13-3110-4a38-a8fe-d6e208788362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar las métricas de entrenamiento y validación\n",
    "def plot_training_history(history):\n",
    "    metrics = ['binary_accuracy', 'precision', 'recall']\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.plot(history.history[metric], label='Entrenamiento')\n",
    "        plt.plot(history.history['val_' + metric], label='Validación')\n",
    "        plt.title(metric.capitalize())\n",
    "        plt.xlabel('Épocas')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d05f44-cc4d-4707-966b-318b0c74ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de validación sin aumentos\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def weighted_binary_crossentropy(class_weights):\n",
    "    # Convertir class_weights a tensor, en caso de que aún no lo sea\n",
    "    class_weights = tf.constant(class_weights, dtype=tf.float32)\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        # Convertir las etiquetas a float32 para evitar problemas de tipo\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Calcula la pérdida binaria por cada etiqueta\n",
    "        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        # Multiplica la pérdida de cada clase por su peso correspondiente.\n",
    "        # Se asume que y_true y bce tienen forma (batch_size, num_classes)\n",
    "        weighted_bce = bce * class_weights\n",
    "        # Se promedia la pérdida a lo largo de las clases y muestras\n",
    "        return tf.reduce_mean(weighted_bce)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    # 1. Cargar el modelo base pre-entrenado (MobileNetV3Large) sin la capa de clasificación final\n",
    "    base_model = tf.keras.applications.MobileNetV3Large(\n",
    "        input_shape=TARGET_SIZE_CHANNEL,\n",
    "        include_preprocessing=True,  # Aplica el preprocesamiento interno\n",
    "        include_top=False,  # Excluimos la parte de clasificación original\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False  # Congelamos las capas del modelo base\n",
    "\n",
    "    # 2. Construir la nueva arquitectura agregando una cabeza de clasificación para multi-label\n",
    "    inputs = tf.keras.Input(shape=TARGET_SIZE_CHANNEL)\n",
    "    # Preprocesamiento específico para MobileNetV3\n",
    "    x = layers.Rescaling(scale=255.0)(inputs)  # Escalar de [0,1] a [0,255]\n",
    "   \n",
    "    # Es posible que necesites redimensionar o normalizar si tus imágenes no cumplen el formato:\n",
    "    x = base_model(x)\n",
    "    \n",
    "    # Capas base del modelo (ejemplo)\n",
    "    x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Capa de salida multi-label\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# 1. Construcción del modelo con MobileNetV3\n",
    "print('build_model...')\n",
    "model = build_model(input_shape=X_bal.shape[1:], num_classes=len(LABEL_COLUMNS))\n",
    "print('build_model OK')\n",
    "\n",
    "print('loss...')\n",
    "# Ejemplo de uso:\n",
    "loss_fn = weighted_binary_crossentropy(class_weights)\n",
    "print('loss OK')\n",
    "\n",
    "# Optimizador con learning rate adaptativo\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# 2. Compilación del modelo\n",
    "print('compile...')\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,  # Loss estándar para multi-label\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "print('compile OK')\n",
    "\n",
    "print('fit inicial...')\n",
    "# 3. Entrenamiento inicial (solo capas nuevas)\n",
    "initial_epochs = 15\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=initial_epochs,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_recall', patience=3, mode='max'),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('fit inicial OK')\n",
    "# Llamada a la función para mostrar las gráficas\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12232b-861b-408d-b6f0-553e170663f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "# Ver arquitectura detallada\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)\n",
    "\n",
    "# 4. Fine-tuning (descongelar capas superiores)\n",
    "# Descongelar las últimas 15 capas del modelo base\n",
    "base_model = model.layers[2]  # Índice de la capa MobileNetV3\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompilar con learning rate más bajo\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Entrenar con fine-tuning\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "print('fit...')\n",
    "history_fine = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_recall', patience=5, mode='max', verbose=1),\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Llamada a la función para mostrar las gráficas\n",
    "plot_training_history(history)\n",
    "print('fit OK')\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "print('save...')\n",
    "model.save(\"mobilenetv3_classifier.v.6.keras\")\n",
    "print('save OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d50a61-9503-4e61-82d1-72dd51d9218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('predict...')\n",
    "# Generar predicciones\n",
    "y_pred = model.predict(val_dataset)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "print('predict OK')\n",
    "\n",
    "# Reporte detallado por clase\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=LABEL_COLUMNS,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d52a6-c6ec-42fe-a0d8-2d8f4814db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "# Acumula las etiquetas verdaderas y las predicciones en listas\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "# Itera sobre el dataset de validación\n",
    "for x_batch, y_batch in val_dataset:\n",
    "    # Genera las predicciones para el batch\n",
    "    preds = model.predict(x_batch)\n",
    "    # Convierte las probabilidades a etiquetas binarias (umbral de 0.5, ajústalo si es necesario)\n",
    "    preds_binary = (preds > 0.5).astype(int)\n",
    "    \n",
    "    y_true_list.append(y_batch.numpy())\n",
    "    y_pred_list.append(preds_binary)\n",
    "\n",
    "# Concatena todos los batches en arreglos completos\n",
    "y_true = np.concatenate(y_true_list, axis=0)\n",
    "y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "\n",
    "# Calcula la matriz de confusión para cada clase\n",
    "mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Recorre y muestra la matriz de confusión de cada clase\n",
    "for i, cm in enumerate(mcm):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=[\"Pred 0\", \"Pred 1\"], \n",
    "                yticklabels=[\"True 0\", \"True 1\"])\n",
    "    plt.title(f\"Matriz de confusión para {LABEL_COLUMNS[i]}\")\n",
    "    plt.ylabel(\"Etiqueta real\")\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1fd510-d7b5-4bb5-b396-75116d733520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
