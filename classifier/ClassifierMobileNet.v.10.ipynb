{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2ca09f-25cd-4dee-a3e4-dfcc5798db4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.17.0\n",
      "keras: 3.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import logging\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"smote_process.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f'tensorflow: {tf.__version__}')\n",
    "print(f'keras: {tf.keras.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4108ac-03e2-4863-af9b-1406c54a88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuración inicial\n",
    "LOCAL_IMAGE_PATH = './repo_dataset'\n",
    "TARGET_SIZE = (224, 224)\n",
    "TARGET_SIZE_CHANNEL = (224, 224, 3)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Columnas de clases\n",
    "LABEL_COLUMNS = ['direccion', 'fachada', 'envio', 'etiqueta']\n",
    "\n",
    "#cargar csv y dividir en dev set y test set\n",
    "# Load the dataset into a DataFrame\n",
    "#CSV_PATH = '.\\mobilnet-multi-label-solo-local.csv'\n",
    "#CSV_PATH = '.\\mobilnet-multi-label.csv'\n",
    "#CSV_PATH = '.\\mobilnet-multi-label-dev-test-50.csv'\n",
    "CSV_PATH = '.\\mobilnet-multi-label-train-80.csv'\n",
    "CSV_PATH_DEV = '.\\mobilnet-multi-label-dev-test-50.csv'\n",
    "CSV_PATH_TEST = '.\\mobilnet-multi-label-test-50.csv'\n",
    "\n",
    "CSV_TRAIN = CSV_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a54ecf-05c1-4960-b458-33765100a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(CSV_PATH_DEV)\n",
    "print(f'Length dataset {len(sample_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb1ec5a-9c96-456e-9f6b-de972612b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar las imagenes\n",
    "def prepare_image(row, local_image_path, label_columns, target_size):\n",
    "    # Preparar las etiquetas\n",
    "    labels = row[label_columns].values.astype(int)\n",
    " \n",
    "    try:\n",
    "        # Cargar desde archivo local\n",
    "        img_path = os.path.join(local_image_path, row['filename'])\n",
    "        if os.path.exists(img_path):\n",
    "            image = Image.open(img_path)\n",
    "        elif pd.notna(row['urlAbsoluta']):    \n",
    "             urlAbsoluta = row['urlAbsoluta']\n",
    "             if 'http' in urlAbsoluta:\n",
    "                 # Descargar la imagen desde la URL\n",
    "                 response = requests.get(row['urlAbsoluta'], stream=True, timeout=10)\n",
    "                 if response.status_code == 200:\n",
    "                     image = Image.open(BytesIO(response.content))\n",
    "                     #guardar local para el siguiente ciclo de entrenamiento/prueba\n",
    "                     image.save(img_path)\n",
    "             elif os.path.exists(urlAbsoluta):\n",
    "                 image = Image.open(urlAbsoluta)\n",
    "             else:\n",
    "                 raise Exception(f'Error cargando {urlAbsoluta}, archivo no encontrado')\n",
    "    \n",
    "        # Convertir a RGB (en caso de que la imagen esté en otro formato, como RGBA)\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # Redimensionar la imagen\n",
    "        image = image.resize(target_size)  # Redimensionar a 224x224 para MobileNetV3\n",
    "        \n",
    "        # Convertir a un array de numpy y normalizar\n",
    "        image = np.array(image) / 255.0  # Normalizar\n",
    "        \n",
    "        return image, np.array(labels)\n",
    "    except BaseException as e:\n",
    "        print(f'Error en: {img_path}, Excepción: {str(e)}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def prepare_dataset(df, local_image_path, label_columns, target_size, max_workers=4):\n",
    "    labels = []\n",
    "    images = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Procesar cada fila del DataFrame\n",
    "        futures = [executor.submit(prepare_image, row, local_image_path, label_columns, target_size) \n",
    "                   for _, row in df.iterrows()]\n",
    "          \n",
    "        # Recolectar resultados con barra de progreso\n",
    "        for future in tqdm(futures, total=len(df)):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                img_array, img_labels = result\n",
    "                images.append(img_array)\n",
    "                labels.append(img_labels)\n",
    "\n",
    "    # Convertir a arrays numpy\n",
    "    X = np.array(images)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def print_class_distribution(X, y, label_columns):\n",
    "    print(f\"Dataset preparado con {len(X)} imágenes\")\n",
    "    print(f\"Distribución de clases:\")\n",
    "    for i, col in enumerate(label_columns):\n",
    "        positive_samples = np.sum(y[:, i])\n",
    "        percentage = (positive_samples / len(y)) * 100\n",
    "        print(f\"{col}: {percentage:.2f}% ({int(positive_samples)}/{len(y)})\")\n",
    "\n",
    "\n",
    "def print_class_distribution_from_csv(csv_path, label_columns):\n",
    "    \"\"\"\n",
    "    Imprime la distribución de clases leyendo desde un archivo CSV\n",
    "    \n",
    "    Parámetros:\n",
    "    csv_path: str - Ruta al archivo CSV\n",
    "    label_columns: list - Lista de nombres de las columnas de etiquetas\n",
    "    \"\"\"\n",
    "    # Leer solo las columnas necesarias del CSV\n",
    "    df = pd.read_csv(csv_path, usecols=label_columns)\n",
    "    total_samples = len(df)\n",
    "    frecuencias = [0] * len(label_columns)\n",
    "    \n",
    "    print(f\"Dataset preparado con {total_samples} imágenes\")\n",
    "    print(f\"Distribución de clases:\")\n",
    "    \n",
    "    for idx, col in enumerate(label_columns):\n",
    "        positive_samples = df[col].sum()\n",
    "        percentage = (positive_samples / total_samples) * 100\n",
    "        print(f\"{col}: {percentage:.2f}% ({int(positive_samples)}/{total_samples})\")\n",
    "        frecuencias[idx] = positive_samples\n",
    "    return total_samples, frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250f78d6-bc4a-4676-8f45-4efb8b36d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loader(csv_path, local_image_path, label_columns, target_size, batch_size=32):\n",
    "    \"\"\"Generador de lotes de ejemplo\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    total_samples = len(df)\n",
    "    \n",
    "    for start in range(0, total_samples, batch_size):\n",
    "        batch = df.iloc[start:start+batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for _, row in batch.iterrows():\n",
    "            result = prepare_image(row, local_image_path, label_columns, target_size)\n",
    "            if result is not None:\n",
    "                img_array, img_labels = result\n",
    "                X_batch.append(img_array)\n",
    "                y_batch.append(img_labels)\n",
    "            else: \n",
    "                continue\n",
    "        \n",
    "        yield np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece36b4-8aef-4d8a-874d-8142dd84ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_test = pd.read_csv(CSV_PATH_TEST)\n",
    "X_test,y_test = prepare_dataset(sample_df_test, LOCAL_IMAGE_PATH, LABEL_COLUMNS, TARGET_SIZE)   \n",
    "print(f'X_test={X_test.shape}, y_test={y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89277932-d57a-4096-a11c-eb0486951d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from typing import Generator, Tuple\n",
    "\n",
    "class MultiLabelSMOTE:\n",
    "    def __init__(self, target_samples=500, k_neighbors=5, output_dir='synthetic', batch_size=100, img_shape=TARGET_SIZE_CHANNEL):\n",
    "        self.target_samples = target_samples\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.batch_size = batch_size\n",
    "        self.output_dir = output_dir\n",
    "        self.csv_path = self.csv_path = os.path.join(output_dir, 'metadata.csv')\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self._init_csv()\n",
    "        \n",
    "        # Estado del proceso\n",
    "        self.class_stats = {\n",
    "            'direccion': {'original': 0, 'synthetic': 0},\n",
    "            'fachada': {'original': 0, 'synthetic': 0},\n",
    "            'envio': {'original': 0, 'synthetic': 0},\n",
    "            'etiqueta': {'original': 0, 'synthetic': 0}\n",
    "        }\n",
    "        self.existing_hashes = set()\n",
    "        self._load_existing_hashes()\n",
    "\n",
    "    def _init_csv(self) -> None:\n",
    "        \"\"\"Inicializa el archivo CSV de metadatos\"\"\"\n",
    "        if not os.path.exists(self.csv_path):\n",
    "            pd.DataFrame(columns=['filename', 'urlAbsoluta', 'direccion', \n",
    "                                'fachada', 'envio', 'etiqueta']).to_csv(self.csv_path, index=False)\n",
    "\n",
    "    def _load_existing_hashes(self) -> None:\n",
    "        \"\"\"Carga hashes existentes de ejecuciones previas\"\"\"\n",
    "        hash_file = os.path.join(self.output_dir, 'image_hashes.txt')\n",
    "        try:\n",
    "            if os.path.exists(hash_file):\n",
    "                with open(hash_file, 'r') as f:\n",
    "                    self.existing_hashes = set(f.read().splitlines())\n",
    "                logger.info(f\"Loaded {len(self.existing_hashes)} existing hashes\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading hashes: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _validate_batch(self, X_batch: np.ndarray, y_batch: np.ndarray) -> None:\n",
    "        \"\"\"Valida el formato de los datos de entrada\"\"\"\n",
    "        # Validar etiquetas binarias\n",
    "        if not np.array_equal(y_batch, y_batch.astype(bool)):\n",
    "            raise ValueError(\"Las etiquetas deben ser valores binarios (0 o 1)\")\n",
    "        \n",
    "        # Validar rango de imágenes\n",
    "        if (X_batch.dtype != np.float32 and X_batch.dtype != np.float64) or np.min(X_batch) < 0 or np.max(X_batch) > 1:\n",
    "            raise ValueError(\"Las imágenes deben estar en formato float32 o float64 y normalizadas [0, 1]\")\n",
    "            \n",
    "        # Validar dimensiones\n",
    "        if y_batch.shape[1] != 4:\n",
    "            raise ValueError(\"Debe haber exactamente 4 etiquetas por muestra\")\n",
    "\n",
    "    def _update_stats(self, y_batch: np.ndarray) -> None:\n",
    "        \"\"\"Actualiza las estadísticas de conteo\"\"\"\n",
    "        for label, idx in zip(['direccion', 'fachada', 'envio', 'etiqueta'], range(4)):\n",
    "            self.class_stats[label]['original'] += y_batch[:, idx].sum()\n",
    "\n",
    "    def _needs_generation(self, label: str) -> bool:\n",
    "        \"\"\"Determina si una clase necesita más muestras\"\"\"\n",
    "        total = self.class_stats[label]['original'] + self.class_stats[label]['synthetic']\n",
    "        return total < self.target_samples\n",
    "\n",
    "    def _generate_safe_samples(self, X_class: np.ndarray, y_class: np.ndarray, \n",
    "                              label: str, pbar: tqdm) -> int:\n",
    "        \"\"\"Genera muestras sintéticas con validaciones\"\"\"\n",
    "        try:\n",
    "            if len(X_class) < self.k_neighbors + 1:\n",
    "                logger.warning(f\"Clase {label}: Muestras insuficientes ({len(X_class)}) para SMOTE\")\n",
    "                return 0\n",
    "\n",
    "            needed = self.target_samples - (self.class_stats[label]['original'] + self.class_stats[label]['synthetic'])\n",
    "            if needed <= 0:\n",
    "                return 0\n",
    "                \n",
    "            print(f'Generando para {label}')\n",
    "            knn = NearestNeighbors(n_neighbors=self.k_neighbors)\n",
    "            knn.fit(X_class.reshape(len(X_class), -1))\n",
    "            \n",
    "            generated = 0\n",
    "            for _ in range(min(needed, self.batch_size)):\n",
    "                i = np.random.randint(0, len(X_class))\n",
    "                neighbor_idx = np.random.choice(knn.kneighbors([X_class[i].flatten()])[1][0])\n",
    "                gap = np.random.uniform(0, 1)\n",
    "                \n",
    "                synthetic = np.clip(X_class[i] + gap * (X_class[neighbor_idx] - X_class[i]), 0, 1)\n",
    "                synth_hash = hashlib.md5(synthetic.tobytes()).hexdigest()\n",
    "                \n",
    "                if synth_hash not in self.existing_hashes:\n",
    "                    self._save_sample(synthetic, y_class[i], label, synth_hash)\n",
    "                    generated += 1\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "            return generated\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generando muestras para {label}: {str(e)}\")\n",
    "            return 0\n",
    "\n",
    "    def _save_sample(self, img_array: np.ndarray, y: np.ndarray, \n",
    "                    label: str, img_hash: str) -> None:\n",
    "        \"\"\"Guarda una muestra individual con registro robusto\"\"\"\n",
    "        try:\n",
    "            filename = f\"synth_{label}_{img_hash[:8]}.jpg\"\n",
    "            filepath = os.path.abspath(os.path.join(self.output_dir, filename))\n",
    "            \n",
    "            # Conversión validada a uint8\n",
    "            if img_array.dtype != np.uint8:\n",
    "                img_array = (img_array * 255).astype(np.uint8)\n",
    "                \n",
    "            Image.fromarray(img_array).save(filepath)\n",
    "            \n",
    "            # Registrar en CSV\n",
    "            pd.DataFrame([{\n",
    "                'filename': filename,\n",
    "                'urlAbsoluta': filepath,\n",
    "                'direccion': int(y[0]),\n",
    "                'fachada': int(y[1]),\n",
    "                'envio': int(y[2]),\n",
    "                'etiqueta': int(y[3])\n",
    "            }]).to_csv(self.csv_path, mode='a', header=False, index=False)\n",
    "            \n",
    "            # Actualizar estado\n",
    "            self.existing_hashes.add(img_hash)\n",
    "            self.class_stats[label]['synthetic'] += 1\n",
    "            \n",
    "            # Registrar hash\n",
    "            with open(os.path.join(self.output_dir, 'image_hashes.txt'), 'a') as f:\n",
    "                f.write(f\"{img_hash}\\n\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error guardando muestra {filename}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _log_progress(self) -> None:\n",
    "        \"\"\"Registra el progreso actual\"\"\"\n",
    "        progress = []\n",
    "        for label in self.class_stats:\n",
    "            total = self.class_stats[label]['original'] + self.class_stats[label]['synthetic']\n",
    "            progress.append(\n",
    "                f\"{label}: {total}/{self.target_samples} \"\n",
    "                f\"({min(100, total/self.target_samples*100):.1f}%)\"\n",
    "            )\n",
    "        logger.info(\"Progreso | \" + \" | \".join(progress))\n",
    "\n",
    "    def fit_resample(self, data_loader: Generator[Tuple[np.ndarray, np.ndarray], None, None]) -> None:\n",
    "        \"\"\"Ejecuta el proceso completo con seguimiento detallado\"\"\"\n",
    "        total_batches = len(data_loader) if hasattr(data_loader, '__len__') else None\n",
    "        progress_desc = \"Procesando dataset \" + (f\" ({total_batches} lotes)\" if total_batches else \"\")\n",
    "        \n",
    "        try:\n",
    "            with tqdm(data_loader, desc=progress_desc, unit=\"batch\", total=total_batches) as batch_pbar:\n",
    "                for batch_idx, (X_batch, y_batch) in enumerate(batch_pbar):\n",
    "                    # Validar lote\n",
    "                    self._validate_batch(X_batch, y_batch)\n",
    "                    \n",
    "                    # Actualizar estadísticas\n",
    "                    self._update_stats(y_batch)\n",
    "                    \n",
    "                    # Procesar cada clase\n",
    "                    with tqdm(total=4, desc=\"Clases\", leave=False) as class_pbar:\n",
    "                        for label in ['direccion', 'fachada', 'envio','etiqueta']:\n",
    "                            if self._needs_generation(label):\n",
    "                                mask = y_batch[:, list(self.class_stats.keys()).index(label)] == 1\n",
    "                                X_class = X_batch[mask]\n",
    "                                y_class = y_batch[mask]\n",
    "                                \n",
    "                                generated = self._generate_safe_samples(X_class, y_class, label, batch_pbar)\n",
    "                                if generated > 0:\n",
    "                                    logger.debug(f\"Lote {batch_idx}: Generadas {generated} para {label}\")\n",
    "                                    \n",
    "                            class_pbar.update(1)\n",
    "                            class_pbar.refresh()\n",
    "                    \n",
    "                    # Liberar memoria\n",
    "                    del X_batch, y_batch\n",
    "                    gc.collect()\n",
    "                    \n",
    "                    # Reporte periódico\n",
    "                    if batch_idx % 10 == 0:\n",
    "                        self._log_progress()\n",
    "                        \n",
    "            # Reporte final\n",
    "            logger.info(\"\\nPROCESO COMPLETADO\")\n",
    "            self._log_progress()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error en el proceso principal: {str(e)}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Cierre seguro de recursos\n",
    "            if 'f' in locals():\n",
    "                f.close()\n",
    "            logger.info(\"Limpieza finalizada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0fdaf5-5e95-499f-93d5-0b1c35e6cfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelSMOTE...\n",
      "Distribución antes de SMOTE\n",
      "Dataset preparado con 22614 imágenes\n",
      "Distribución de clases:\n",
      "direccion: 21.80% (4929/22614)\n",
      "fachada: 23.79% (5379/22614)\n",
      "envio: 65.46% (14802/22614)\n",
      "etiqueta: 50.42% (11401/22614)\n",
      "Frecuencia de cada etiqueta: [4929, 5379, 14802, 11401]\n",
      "La etiqueta que más aparece es la 2 con 14802 apariciones\n",
      "Umbral de generación: 14061\n",
      "Generando data sintética...\n",
      "{'direccion': True, 'fachada': True, 'envio': False, 'etiqueta': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 0batch [00:00, ?batch/s]\n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 457batch [00:31, 21.93batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:23<01:10, 23.54s/it]\n",
      "Procesando dataset : 460batch [00:31, 17.60batch/s]                                      | 1/4 [00:23<01:10, 23.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 907batch [00:53, 18.50batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:45<00:45, 22.90s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:45<00:45, 22.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 1397batch [01:29, 13.78batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:21<00:28, 28.77s/it]\n",
      "Procesando dataset : 1399batch [01:29,  9.33batch/s]██████████████████                   | 3/4 [01:21<00:28, 28.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 1859batch [02:01, 16.77batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:54<00:00, 30.20s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:54<00:00, 30.20s/it]\n",
      "\u001b[A2025-03-04 07:59:56,611 - INFO - Progreso | direccion: 565/14061 (4.0%) | fachada: 551/14061 (3.9%) | envio: 785/14061 (5.6%) | etiqueta: 702/14061 (5.0%)\n",
      "\n",
      "Procesando dataset : 1861batch [02:10,  1.29s/batch]                                             | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 2328batch [02:34, 19.89batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:24<01:13, 24.41s/it]\n",
      "Procesando dataset : 2332batch [02:34, 16.68batch/s]                                     | 1/4 [00:24<01:13, 24.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 2777batch [02:59, 16.58batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:49<00:50, 25.02s/it]\n",
      "Procesando dataset : 2780batch [03:00, 11.54batch/s]                                     | 2/4 [00:49<00:50, 25.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 3262batch [03:33, 14.78batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:23<00:29, 29.06s/it]\n",
      "Procesando dataset : 3264batch [03:34, 11.41batch/s]██████████████████                   | 3/4 [01:23<00:29, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 3716batch [04:02, 17.18batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:52<00:00, 29.05s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:52<00:00, 29.05s/it]\n",
      "Procesando dataset : 3718batch [04:03, 14.69batch/s]                                                                   \n",
      "Procesando dataset : 3720batch [04:10,  1.21s/batch]                                             | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 4191batch [04:34, 19.32batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:24<01:12, 24.13s/it]\n",
      "Procesando dataset : 4193batch [04:34, 15.76batch/s]                                     | 1/4 [00:24<01:12, 24.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 4640batch [05:00, 18.05batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:49<00:50, 25.03s/it]\n",
      "Procesando dataset : 4642batch [05:00, 12.11batch/s]                                     | 2/4 [00:49<00:50, 25.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 5124batch [05:34, 14.93batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:24<00:29, 29.26s/it]\n",
      "Procesando dataset : 5126batch [05:35, 10.97batch/s]██████████████████                   | 3/4 [01:24<00:29, 29.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 5590batch [06:04, 14.88batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:54<00:00, 29.54s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:54<00:00, 29.54s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 5592batch [06:12,  1.25s/batch]                                             | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 6059batch [06:37, 18.91batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:25<01:15, 25.28s/it]\n",
      "Procesando dataset : 6061batch [06:38, 16.32batch/s]                                     | 1/4 [00:25<01:15, 25.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 6511batch [07:02, 18.79batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:50<00:50, 25.11s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:50<00:50, 25.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 6991batch [07:40, 12.12batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:27<00:30, 30.65s/it]\n",
      "Procesando dataset : 6993batch [07:40,  9.18batch/s]██████████████████                   | 3/4 [01:27<00:30, 30.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 7447batch [08:12, 14.26batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:59<00:00, 31.17s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:59<00:00, 31.17s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 7449batch [08:20,  1.25s/batch]                                             | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 7919batch [08:45, 17.50batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:25<01:16, 25.37s/it]\n",
      "Procesando dataset : 7921batch [08:45, 14.34batch/s]                                     | 1/4 [00:25<01:16, 25.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 8364batch [09:10, 17.23batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:50<00:50, 25.38s/it]\n",
      "Procesando dataset : 8366batch [09:10, 11.46batch/s]                                     | 2/4 [00:50<00:50, 25.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 8846batch [09:46, 10.88batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:26<00:30, 30.19s/it]\n",
      "Procesando dataset : 8848batch [09:46,  7.96batch/s]██████████████████                   | 3/4 [01:26<00:30, 30.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 9322batch [10:18, 14.29batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:58<00:00, 30.89s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:58<00:00, 30.89s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 9324batch [10:26,  1.31s/batch]                                             | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 9794batch [10:51, 16.28batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:25<01:15, 25.22s/it]\n",
      "Procesando dataset : 9796batch [10:52, 14.01batch/s]                                     | 1/4 [00:25<01:15, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 10232batch [11:15, 20.32batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:48<00:48, 24.12s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:48<00:48, 24.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 10713batch [11:52, 13.17batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:25<00:30, 30.17s/it]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:25<00:30, 30.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 11175batch [12:24, 14.66batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:58<00:00, 30.94s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:58<00:00, 30.94s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 11177batch [12:32,  1.25s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 11634batch [13:00, 16.53batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:27<01:23, 28.00s/it]\n",
      "Procesando dataset : 11636batch [13:00, 12.74batch/s]                                    | 1/4 [00:28<01:23, 28.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 12051batch [13:27, 17.61batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:54<00:54, 27.21s/it]\n",
      "Procesando dataset : 12053batch [13:27, 10.27batch/s]                                    | 2/4 [00:54<00:54, 27.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 12533batch [14:04, 13.20batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:31<00:31, 31.74s/it]\n",
      "Procesando dataset : 12535batch [14:04,  9.91batch/s]█████████████████                   | 3/4 [01:31<00:31, 31.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 12991batch [14:36, 12.30batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:04<00:00, 31.98s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:04<00:00, 31.98s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 12995batch [14:45,  1.07batch/s]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 13468batch [15:12, 17.67batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:27<01:23, 27.69s/it]\n",
      "Procesando dataset : 13470batch [15:12, 14.21batch/s]                                    | 1/4 [00:27<01:23, 27.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 13928batch [15:39, 15.61batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:54<00:53, 26.95s/it]\n",
      "Procesando dataset : 13930batch [15:39, 11.44batch/s]                                    | 2/4 [00:54<00:53, 26.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 14412batch [16:12, 12.16batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:27<00:30, 30.08s/it]\n",
      "Procesando dataset : 14414batch [16:13,  8.88batch/s]█████████████████                   | 3/4 [01:27<00:30, 30.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 14868batch [16:48, 12.13batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:03<00:00, 32.31s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:03<00:00, 32.31s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 14870batch [16:59,  1.67s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 15332batch [17:26, 19.29batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:27<01:21, 27.18s/it]\n",
      "Procesando dataset : 15337batch [17:26, 16.59batch/s]                                    | 1/4 [00:27<01:21, 27.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 15786batch [17:52, 18.61batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:53<00:53, 26.68s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:53<00:53, 26.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 16268batch [18:25, 13.94batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:26<00:29, 29.66s/it]\n",
      "Procesando dataset : 16270batch [18:26, 10.57batch/s]█████████████████                   | 3/4 [01:26<00:29, 29.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 16724batch [18:54, 16.07batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:55<00:00, 29.22s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:55<00:00, 29.22s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 16728batch [19:02,  1.07batch/s]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 17200batch [19:31, 15.88batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:28<01:26, 28.76s/it]\n",
      "Procesando dataset : 17202batch [19:31, 11.45batch/s]                                    | 1/4 [00:28<01:26, 28.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 17660batch [19:58, 16.71batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:56<00:56, 28.10s/it]\n",
      "Procesando dataset : 17662batch [19:59, 10.46batch/s]                                    | 2/4 [00:56<00:56, 28.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 18140batch [20:29, 14.90batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:27<00:29, 29.44s/it]\n",
      "Procesando dataset : 18144batch [20:30, 13.17batch/s]█████████████████                   | 3/4 [01:27<00:29, 29.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 18591batch [20:56, 13.95batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:54<00:00, 28.44s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:54<00:00, 28.44s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 18593batch [21:04,  1.25s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 19057batch [21:30, 17.13batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:25<01:16, 25.54s/it]\n",
      "Procesando dataset : 19059batch [21:30, 13.29batch/s]                                    | 1/4 [00:25<01:16, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 19514batch [21:57, 18.10batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:52<00:53, 26.51s/it]\n",
      "Procesando dataset : 19516batch [21:57, 12.15batch/s]                                    | 2/4 [00:52<00:53, 26.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 20006batch [22:31, 14.49batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:26<00:29, 29.79s/it]\n",
      "Procesando dataset : 20008batch [22:31, 12.10batch/s]█████████████████                   | 3/4 [01:26<00:29, 29.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 20462batch [22:58, 15.53batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:53<00:00, 28.90s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:53<00:00, 28.90s/it]\n",
      "\u001b[A2025-03-04 08:20:53,344 - INFO - Progreso | direccion: 6612/14061 (47.0%) | fachada: 6519/14061 (46.4%) | envio: 8431/14061 (60.0%) | etiqueta: 7462/14061 (53.1%)\n",
      "\n",
      "Procesando dataset : 20464batch [23:07,  1.36s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 20902batch [23:29, 21.67batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:22<01:08, 22.72s/it]\n",
      "Procesando dataset : 20907batch [23:30, 19.32batch/s]                                    | 1/4 [00:22<01:08, 22.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 21344batch [23:52, 19.04batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:45<00:45, 22.62s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:45<00:45, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 21832batch [24:32, 12.54batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:25<00:30, 30.46s/it]\n",
      "Procesando dataset : 21834batch [24:32,  9.47batch/s]█████████████████                   | 3/4 [01:25<00:30, 30.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 22300batch [25:05, 12.61batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:58<00:00, 31.67s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:58<00:00, 31.67s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 22302batch [25:14,  1.30s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 22765batch [25:36, 19.65batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:22<01:07, 22.42s/it]\n",
      "Procesando dataset : 22769batch [25:36, 17.48batch/s]                                    | 1/4 [00:22<01:07, 22.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 23201batch [25:58, 19.70batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:45<00:45, 22.52s/it]\n",
      "Procesando dataset : 23203batch [25:59, 11.19batch/s]                                    | 2/4 [00:45<00:45, 22.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 23682batch [26:41, 10.91batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:27<00:31, 31.63s/it]\n",
      "Procesando dataset : 23684batch [26:41,  8.12batch/s]█████████████████                   | 3/4 [01:27<00:31, 31.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 24156batch [27:16, 14.63batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:02<00:00, 33.02s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:02<00:00, 33.02s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 24158batch [27:24,  1.23s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 24612batch [27:53, 17.62batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:28<01:26, 28.98s/it]\n",
      "Procesando dataset : 24614batch [27:53, 12.73batch/s]                                    | 1/4 [00:28<01:26, 28.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 25048batch [28:20, 15.84batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:55<00:55, 27.72s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:55<00:55, 27.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 25530batch [29:05, 10.84batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:41<00:35, 35.93s/it]\n",
      "Procesando dataset : 25532batch [29:06,  8.50batch/s]█████████████████                   | 3/4 [01:41<00:35, 35.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 25990batch [29:41, 11.52batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:17<00:00, 35.77s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:17<00:00, 35.77s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 25992batch [29:49,  1.29s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 26462batch [30:17, 18.03batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:28<01:24, 28.12s/it]\n",
      "Procesando dataset : 26464batch [30:17, 14.68batch/s]                                    | 1/4 [00:28<01:24, 28.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 26893batch [30:43, 15.11batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:54<00:53, 26.87s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:54<00:53, 26.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 27378batch [31:29, 10.29batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:40<00:35, 35.65s/it]\n",
      "Procesando dataset : 27380batch [31:29,  8.12batch/s]█████████████████                   | 3/4 [01:40<00:35, 35.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 27840batch [32:08, 13.02batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:18<00:00, 36.77s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:18<00:00, 36.77s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 27844batch [32:16,  1.05batch/s]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 28298batch [32:43, 14.28batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:26<01:20, 26.69s/it]\n",
      "Procesando dataset : 28300batch [32:43, 12.07batch/s]                                    | 1/4 [00:26<01:20, 26.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 28718batch [33:10, 14.89batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:54<00:54, 27.17s/it]\n",
      "Procesando dataset : 28720batch [33:11,  9.36batch/s]                                    | 2/4 [00:54<00:54, 27.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 29203batch [33:56,  9.55batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:40<00:35, 35.72s/it]\n",
      "Procesando dataset : 29204batch [33:56,  6.94batch/s]█████████████████                   | 3/4 [01:40<00:35, 35.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 29662batch [34:33, 12.40batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:17<00:00, 36.20s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:17<00:00, 36.20s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 29664batch [34:41,  1.30s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 30100batch [35:07, 16.83batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:26<01:18, 26.02s/it]\n",
      "Procesando dataset : 30102batch [35:07, 13.53batch/s]                                    | 1/4 [00:26<01:18, 26.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 30519batch [35:33, 18.78batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:51<00:51, 25.94s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:51<00:51, 25.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 31003batch [36:21,  9.68batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:39<00:35, 35.79s/it]\n",
      "Procesando dataset : 31004batch [36:21,  6.25batch/s]█████████████████                   | 3/4 [01:39<00:35, 35.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 31463batch [37:02, 10.30batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:20<00:00, 38.07s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [02:20<00:00, 38.07s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 31465batch [37:10,  1.24s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 31884batch [37:32, 17.83batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:22<01:06, 22.08s/it]\n",
      "Procesando dataset : 31887batch [37:32, 17.47batch/s]                                    | 1/4 [00:22<01:06, 22.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 32299batch [37:53, 21.01batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:43<00:42, 21.45s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:43<00:42, 21.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para envio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 32310batch [37:54, 11.38batch/s]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [00:44<00:12, 12.29s/it]\n",
      "Procesando dataset : 32312batch [37:55,  6.70batch/s]█████████████████                   | 3/4 [00:44<00:12, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 32798batch [38:42, 10.57batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:32<00:00, 26.28s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:32<00:00, 26.28s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 32800batch [38:50,  1.34s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 33230batch [39:16, 17.90batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:25<01:17, 25.78s/it]\n",
      "Procesando dataset : 33234batch [39:16, 16.09batch/s]                                    | 1/4 [00:25<01:17, 25.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 33660batch [39:40, 19.11batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:50<00:50, 25.21s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:50<00:50, 25.21s/it]\n",
      "Procesando dataset : 33662batch [39:41, 10.69batch/s]█████████████████                   | 3/4 [00:50<00:25, 25.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 34146batch [40:26, 10.36batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:36<00:00, 23.68s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:36<00:00, 23.68s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 34150batch [40:34,  1.09batch/s]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 34588batch [41:00, 15.11batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:26<01:19, 26.39s/it]\n",
      "Procesando dataset : 34590batch [41:00, 13.66batch/s]                                    | 1/4 [00:26<01:19, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 35022batch [41:26, 15.54batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:51<00:51, 25.89s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:51<00:51, 25.89s/it]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [00:51<00:25, 25.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para etiqueta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 35295batch [41:51, 10.84batch/s]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:16<00:00, 17.52s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:16<00:00, 17.52s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 35297batch [41:59,  1.26s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 35717batch [42:23, 18.49batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:24<01:12, 24.02s/it]\n",
      "Procesando dataset : 35721batch [42:23, 16.89batch/s]                                    | 1/4 [00:24<01:12, 24.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 36131batch [42:47, 14.55batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:48<00:48, 24.28s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:48<00:48, 24.28s/it]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [00:48<00:24, 24.28s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [00:48<00:00, 24.28s/it]\n",
      "\u001b[A2025-03-04 08:40:42,446 - INFO - Progreso | direccion: 11749/14061 (83.6%) | fachada: 11491/14061 (81.7%) | envio: 15310/14061 (100.0%) | etiqueta: 14431/14061 (100.0%)\n",
      "\n",
      "Procesando dataset : 36133batch [42:56,  1.43s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 36570batch [43:21, 18.94batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:24<01:14, 24.87s/it]\n",
      "Procesando dataset : 36572batch [43:21, 16.39batch/s]                                    | 1/4 [00:24<01:14, 24.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 36989batch [43:46, 18.88batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:49<00:50, 25.01s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:49<00:50, 25.01s/it]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [00:49<00:25, 25.01s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [00:49<00:00, 25.01s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 36991batch [43:54,  1.16s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 37443batch [44:22, 16.76batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:28<01:25, 28.48s/it]\n",
      "Procesando dataset : 37447batch [44:23, 15.15batch/s]                                    | 1/4 [00:28<01:25, 28.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 37862batch [44:49, 13.98batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:55<00:55, 27.51s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:55<00:55, 27.51s/it]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [00:55<00:27, 27.51s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [00:55<00:00, 27.51s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 37864batch [45:00,  1.59s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 38338batch [45:32, 12.31batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:33<01:39, 33.17s/it]\n",
      "Procesando dataset : 38340batch [45:33, 10.52batch/s]                                    | 1/4 [00:33<01:39, 33.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 38794batch [46:09, 12.89batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [01:09<01:09, 34.86s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [01:09<01:09, 34.86s/it]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:09<00:34, 34.86s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:09<00:00, 34.86s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "Procesando dataset : 38796batch [46:17,  1.33s/batch]                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para direccion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 39264batch [46:52, 12.98batch/s]\n",
      "\u001b[Ases:  25%|███████████████████                                                         | 1/4 [00:35<01:45, 35.28s/it]\n",
      "Procesando dataset : 39266batch [46:52,  9.11batch/s]                                    | 1/4 [00:35<01:45, 35.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 39720batch [47:32, 12.62batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [01:14<01:15, 37.88s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [01:14<01:15, 37.88s/it]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [01:14<00:37, 37.88s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [01:14<00:00, 37.88s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 999.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando para fachada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dataset : 39821batch [47:51, 11.33batch/s]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:09<00:09,  4.95s/it]\n",
      "\u001b[Ases:  50%|██████████████████████████████████████                                      | 2/4 [00:09<00:09,  4.95s/it]\n",
      "\u001b[Ases:  75%|█████████████████████████████████████████████████████████                   | 3/4 [00:09<00:04,  4.95s/it]\n",
      "\u001b[Ases: 100%|████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  4.95s/it]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 988.06it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 455.75it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 351.88it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 290.88it/s]\n",
      "Procesando dataset : 39822batch [48:01, 11.33batch/s]                                                                  \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 498.20it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 246.33it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 257.42it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 259.46it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 656.08it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 413.86it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 374.96it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 332.05it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 949.58it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 404.45it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 423.44it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 377.16it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 485.79it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 349.74it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 305.06it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 285.14it/s]\n",
      "\u001b[A2025-03-04 08:46:27,268 - INFO - Progreso | direccion: 15042/14061 (100.0%) | fachada: 15037/14061 (100.0%) | envio: 18174/14061 (100.0%) | etiqueta: 16817/14061 (100.0%)\n",
      "\n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 649.98it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 564.62it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 344.74it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 330.59it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 667.25it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 393.50it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 326.35it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 313.04it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▌                                                       | 1/4 [00:00<00:00, 1962.71it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 658.45it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 349.92it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 329.92it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 894.88it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 476.38it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 397.51it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 375.58it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 982.96it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 393.57it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 412.74it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 369.15it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 654.13it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 438.64it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 395.60it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 378.02it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 974.74it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 361.11it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 351.31it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 331.21it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 850.43it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 446.51it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 347.93it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 372.86it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 656.49it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 433.70it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 285.11it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 284.31it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|█████████████████████                                                               | 1/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 461.93it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 407.72it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 404.69it/s]\n",
      "\u001b[A2025-03-04 08:47:45,241 - INFO - Progreso | direccion: 16087/14061 (100.0%) | fachada: 16135/14061 (100.0%) | envio: 21539/14061 (100.0%) | etiqueta: 19430/14061 (100.0%)\n",
      "\n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|█████████████████████                                                               | 1/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 704.45it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 509.00it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 403.28it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 885.06it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 443.61it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 455.97it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 397.45it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 976.33it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 488.56it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 398.17it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 384.69it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 654.13it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 396.32it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 311.98it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 329.09it/s]\n",
      "\u001b[A                                                                                                                    \n",
      "\u001b[Ases:   0%|                                                                                    | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[Ases:  25%|██████████████████▊                                                        | 1/4 [00:00<00:00, 847.85it/s]\n",
      "\u001b[Ases:  50%|█████████████████████████████████████▌                                     | 2/4 [00:00<00:00, 496.81it/s]\n",
      "\u001b[Ases:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:00<00:00, 379.70it/s]\n",
      "\u001b[Ases: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 366.65it/s]\n",
      "Procesando dataset : 46batch [50:24, 65.75s/batch]                                                                     \n",
      "2025-03-04 08:48:18,798 - INFO - \n",
      "PROCESO COMPLETADO\n",
      "2025-03-04 08:48:18,799 - INFO - Progreso | direccion: 16379/14061 (100.0%) | fachada: 16430/14061 (100.0%) | envio: 23041/14061 (100.0%) | etiqueta: 20481/14061 (100.0%)\n",
      "2025-03-04 08:48:18,801 - INFO - Limpieza finalizada\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de data sintética generada con SMOTE\n",
      "Dataset preparado con 39820 imágenes\n",
      "Distribución de clases:\n",
      "direccion: 47.53% (18927/39820)\n",
      "fachada: 49.19% (19587/39820)\n",
      "envio: 41.00% (16328/39820)\n",
      "etiqueta: 36.06% (14359/39820)\n",
      "MultiLabelSMOTE OK\n"
     ]
    }
   ],
   "source": [
    "# 2. Cargar modelo base (MobileNetV3 Large)\n",
    "# Aplicar SMOTE adaptado\n",
    "print('MultiLabelSMOTE...')\n",
    "# calcular la mínima cantidad de muestrar a generar con un grado de tolerancia\n",
    "# Suma por columna para obtener la frecuencia de cada etiqueta\n",
    " # Leer solo las columnas necesarias del CSV\n",
    "print('Distribución antes de SMOTE')\n",
    "total_samples, frecuencias = print_class_distribution_from_csv(CSV_TRAIN, LABEL_COLUMNS)\n",
    "# Obtener el valor máximo (la cantidad máxima de veces que aparece una etiqueta)\n",
    "max_frecuencia = np.max(frecuencias)\n",
    "# Ver cuál etiqueta es la que más aparece\n",
    "etiqueta_mas_comun = np.argmax(frecuencias) \n",
    "\n",
    "print(f'Frecuencia de cada etiqueta: {frecuencias}')\n",
    "print(f'La etiqueta que más aparece es la {etiqueta_mas_comun} con {max_frecuencia} apariciones')\n",
    "max_frecuencia = int(max_frecuencia - (max_frecuencia * 0.05))\n",
    "print(f'Umbral de generación: {max_frecuencia}')\n",
    "\n",
    "print('Generando data sintética...')\n",
    "# Configurar con batch_size pequeño para baja memoria\n",
    "mlsmote = MultiLabelSMOTE(\n",
    "    target_samples=max_frecuencia,\n",
    "    output_dir='./synthetic_data',\n",
    "    batch_size=500  # Ajustar según memoria disponible\n",
    ")\n",
    "\n",
    "mlsmote.needs_smote = {\n",
    "            'direccion': frecuencias[0] < max_frecuencia,\n",
    "            'fachada': frecuencias[1] < max_frecuencia,\n",
    "            'envio': frecuencias[2] < max_frecuencia,\n",
    "            'etiqueta': frecuencias[3] < max_frecuencia,\n",
    "        }\n",
    "\n",
    "mlsmote.original_counts = {\n",
    "            'direccion': frecuencias[0],\n",
    "            'fachada': frecuencias[1],\n",
    "            'envio': frecuencias[2],\n",
    "            'etiqueta': frecuencias[3]\n",
    "        }\n",
    "\n",
    "print(mlsmote.needs_smote)\n",
    "\n",
    "# Ejecución\n",
    "mlsmote.fit_resample(batch_loader(csv_path=CSV_TRAIN, local_image_path=LOCAL_IMAGE_PATH, label_columns=LABEL_COLUMNS, target_size=TARGET_SIZE, batch_size=500))\n",
    "\n",
    "print('Distribución de data sintética generada con SMOTE')\n",
    "print_class_distribution_from_csv('./synthetic_data/metadata.csv', label_columns=LABEL_COLUMNS)\n",
    "print('MultiLabelSMOTE OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c1ca9a-00e2-46b1-a8b4-160ffe502c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('./synthetic_data/metadata.csv')\n",
    "for label in ['direccion', 'fachada', 'envio', 'etiqueta']:\n",
    "    count = df_final[label].sum()\n",
    "    print(f\"Muestras para {label}: {count} (Objetivo: {mlsmote.target_samples})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3721af-fd48-43b1-ae72-131ae3be001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size, img_size, local_image_path, label_columns, shuffle=True):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(dataframe))\n",
    "        self.on_epoch_end()\n",
    "        self.local_image_path = local_image_path\n",
    "        self.label_columns = label_columns\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_data = self.dataframe.iloc[batch_indices]\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for _, row in batch_data.iterrows():\n",
    "            result = prepare_image(row, self.local_image_path, self.label_columns, self.img_size)\n",
    "\n",
    "            if result is not None:\n",
    "                img, label = result\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            else: \n",
    "                print('Continuando por:', row['filename'])\n",
    "                print('Continuando...')\n",
    "                continue\n",
    "            \n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "955a14bf-2e6f-4024-aff7-327d993c9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calcular pesos de clases adaptativos\n",
    "def calculate_class_weights(labels, alpha=0.7, smooth=1e-6):\n",
    "    class_counts = np.sum(labels, axis=0) + smooth\n",
    "    weights = (1 / class_counts) ** alpha  # Mayor énfasis en clases minoritarias\n",
    "    return weights / np.max(weights)  # Normalización a [0, 1]\n",
    "\n",
    "def weighted_binary_crossentropy(class_weights):\n",
    "    # Convertir class_weights a tensor, en caso de que aún no lo sea\n",
    "    class_weights = tf.constant(class_weights, dtype=tf.float32)\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        # Convertir las etiquetas a float32 para evitar problemas de tipo\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Calcula la pérdida binaria por cada etiqueta\n",
    "        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        # Multiplica la pérdida de cada clase por su peso correspondiente.\n",
    "        # Se asume que y_true y bce tienen forma (batch_size, num_classes)\n",
    "        weighted_bce = bce * class_weights\n",
    "        # Se promedia la pérdida a lo largo de las clases y muestras\n",
    "        return tf.reduce_mean(weighted_bce)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 1. Data Augmentation para robustecer el entrenamiento\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2)\n",
    "])\n",
    "\n",
    "def build_model(num_classes):\n",
    "    # 1. Cargar el modelo base pre-entrenado (MobileNetV3Large) sin la capa de clasificación final\n",
    "    base_model = tf.keras.applications.MobileNetV3Large(\n",
    "        input_shape=TARGET_SIZE_CHANNEL,\n",
    "        include_preprocessing=False, # las imagnes de entrada estan normalizadas [0,1] y el modelo espera [0,255]\n",
    "        include_top=False,  # Excluimos la parte de clasificación original\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False  # Congelamos las capas del modelo base\n",
    "\n",
    "    # Construir la nueva arquitectura agregando una cabeza de clasificación para multi-label\n",
    "    inputs = tf.keras.Input(shape=TARGET_SIZE_CHANNEL)\n",
    "    # Aplicar data augmentation PRIMERO (en [0,1])\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # Luego normalizar a [-1,1]\n",
    "    x = layers.Rescaling(scale=2.0, offset=-1.0)(x)  # Mapea [0,1] a [-1,1]\n",
    "\n",
    "    # Pasar por la base pre-entrenada (no se necesita rescaling adicional)\n",
    "    x = base_model(x, training=False)  # training=False mantiene fijos los parámetros de BatchNorm\n",
    "    \n",
    "    # Utilizar GlobalAveragePooling2D para aplanar la salida del base model\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Agregar capa densa con regularización L2, BatchNormalization y Dropout\n",
    "    x = layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Capa de salida para multi-label con activación sigmoide\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b59f742-a2d7-4502-961b-586b2b7bbb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar las métricas de entrenamiento y validación\n",
    "def plot_training_history(history):\n",
    "   # metrics = ['binary_accuracy', 'precision', 'recall']\n",
    "    metrics = ['f1_macro', 'f1_micro']\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.plot(history.history[metric], label='Entrenamiento')\n",
    "        plt.plot(history.history['val_' + metric], label='Validación')\n",
    "        plt.title(metric.capitalize())\n",
    "        plt.xlabel('Épocas')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e8f1484-9826-4d82-9859-03d6893917ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparado con 2824 imágenes sin SOMTE\n",
      "Distribución de clases sin SMOTE:\n",
      "direccion: 21.49% (607/2824)\n",
      "fachada: 23.16% (654/2824)\n",
      "envio: 65.62% (1853/2824)\n",
      "etiqueta: 50.18% (1417/2824)\n",
      "2824 [607, 654, 1853, 1417]\n",
      "frecuencia=[607, 654, 1853, 1417], alpha=[0.785056657223796, 0.768413597733711, 0.3438385269121813, 0.49822946175637395]\n"
     ]
    }
   ],
   "source": [
    "# calcular frecuencias de las clases del set de entrenamiento antes de smote\n",
    "def print_class_distribution_from_csv_no_SMOTE(csv_path, label_columns):\n",
    "    \"\"\"\n",
    "    Imprime la distribución de clases leyendo desde un archivo CSV\n",
    "    \n",
    "    Parámetros:\n",
    "    csv_path: str - Ruta al archivo CSV\n",
    "    label_columns: list - Lista de nombres de las columnas de etiquetas\n",
    "    \"\"\"\n",
    "    # Leer solo las columnas necesarias del CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df['filename'].str.startswith('synth_')==False]\n",
    "    total_samples = len(df)\n",
    "    frecuencias = [0] * len(label_columns)\n",
    "    \n",
    "    print(f\"Dataset preparado con {total_samples} imágenes sin SOMTE\")\n",
    "    print(f\"Distribución de clases sin SMOTE:\")\n",
    "    \n",
    "    for idx, col in enumerate(label_columns):\n",
    "        positive_samples = df[col].sum()\n",
    "        percentage = (positive_samples / total_samples) * 100\n",
    "        print(f\"{col}: {percentage:.2f}% ({int(positive_samples)}/{total_samples})\")\n",
    "        frecuencias[idx] = positive_samples\n",
    "    return total_samples, frecuencias\n",
    "\n",
    "total_samples, frecuencias = print_class_distribution_from_csv_no_SMOTE(CSV_TRAIN, LABEL_COLUMNS)\n",
    "print(total_samples, frecuencias)\n",
    "alpha = [n / total_samples for n in frecuencias]  \n",
    "alpha = [1 - n for n in alpha]  \n",
    "print(f'frecuencia={frecuencias}, alpha={alpha}')\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', threshold=0.5, **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Aplicamos el umbral a las predicciones\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        tp = tf.reduce_sum(y_true * y_pred)\n",
    "        fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "        fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "        \n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "    \n",
    "    def result(self):\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.false_negatives.assign(0)\n",
    "\n",
    "\n",
    "class F1ScoreMacro(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, threshold=0.5, name='f1_macro', **kwargs):\n",
    "        super(F1ScoreMacro, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.threshold = threshold\n",
    "        self.f1_per_class = [F1Score(threshold=threshold) for _ in range(num_classes)]\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        for i in range(self.num_classes):\n",
    "            self.f1_per_class[i].update_state(y_true[:, i], y_pred[:, i], sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.reduce_mean([f1.result() for f1 in self.f1_per_class])\n",
    "\n",
    "    def reset_state(self):\n",
    "        for f1 in self.f1_per_class:\n",
    "            f1.reset_states()\n",
    "\n",
    "class F1ScoreMicro(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=0.5, name='f1_micro', **kwargs):\n",
    "        super(F1ScoreMicro, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        self.true_positives.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "        self.false_positives.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "        self.false_negatives.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.false_negatives.assign(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc32f3-f45f-495e-b12c-8cce9d5a0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Construcción del modelo con MobileNetV3\n",
    "print('build_model...')\n",
    "#y_bal = y_train\n",
    "model = build_model(num_classes=len(LABEL_COLUMNS))\n",
    "print('build_model OK')\n",
    "\n",
    "print('loss...')\n",
    "# Ejemplo de uso:\n",
    "#class_weights = calculate_class_weights(y_bal, alpha=0.7)\n",
    "#loss_fn = weighted_binary_crossentropy(class_weights)\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryFocalCrossentropy(gamma=2.0, alpha=alpha)\n",
    "print('loss OK')\n",
    "\n",
    "# Optimizador con learning rate adaptativo\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "num_classes = len(LABEL_COLUMNS)\n",
    "# F1-score macro promedia la F1 de cada clase.\n",
    "f1_macro = F1ScoreMacro(num_classes=num_classes, threshold=0.5)\n",
    "\n",
    "# F1-score micro calcula la F1 global (acumulando TP, FP, FN de todas las clases).\n",
    "f1_micro = F1ScoreMicro(threshold=0.5)\n",
    "\n",
    "# 2. Compilación del modelo\n",
    "print('compile...')\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    #loss='binary_crossentropy',  # Loss estándar para multi-label\n",
    "    metrics=[f1_macro, f1_micro]\n",
    ")\n",
    "print('compile OK')\n",
    "\n",
    "\n",
    "print('fit inicial...')\n",
    "# Crear generadores\n",
    "train_df = pd.read_csv(CSV_TRAIN)\n",
    "val_df = pd.read_csv(CSV_PATH_TEST)\n",
    "print(f'Length dataset {len(train_df)}')\n",
    "print('distribución train set...')\n",
    "print_class_distribution_from_csv(CSV_TRAIN, label_columns=LABEL_COLUMNS)\n",
    "print('distribución test set...')\n",
    "print_class_distribution_from_csv(CSV_PATH_TEST, label_columns=LABEL_COLUMNS)\n",
    "\n",
    "train_gen = CustomDataGenerator(train_df, BATCH_SIZE, TARGET_SIZE, LOCAL_IMAGE_PATH, label_columns=LABEL_COLUMNS)\n",
    "val_gen = CustomDataGenerator(val_df, BATCH_SIZE, TARGET_SIZE, LOCAL_IMAGE_PATH, label_columns=LABEL_COLUMNS, shuffle=False)\n",
    "\n",
    "# 3. Entrenamiento inicial (solo capas nuevas)\n",
    "initial_epochs = 15\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('fit inicial OK')\n",
    "# Llamada a la función para mostrar las gráficas\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "764eef3f-bcf0-4b72-947a-4d489b09b3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de muestras: 2808\n",
      "Shape de etiquetas: (2808, 4)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class KFoldDataGenerator(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size=32, shuffle=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Usamos ceil para cubrir todos los ejemplos, incluso si el total no es múltiplo exacto de batch_size\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.file_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Índices del batch actual\n",
    "        batch_indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        labels_batch = []\n",
    "        for i in batch_indexes:\n",
    "            columnas = ['filename', 'urlAbsoluta', 'direccion', 'fachada', 'envio', 'etiqueta']\n",
    "            df = pd.DataFrame(columns=columnas)\n",
    "            new_row = {\n",
    "                'filename': self.file_paths[i],\n",
    "                'urlAbsoluta': '',\n",
    "                'direccion': self.labels[i][0],\n",
    "                'fachada': self.labels[i][1],\n",
    "                'envio': self.labels[i][2],\n",
    "                'etiqueta': self.labels[i][3]\n",
    "            }\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            row = ultima_fila_iloc = df.iloc[len(df) - 1]      \n",
    "            result = prepare_image(row, LOCAL_IMAGE_PATH, LABEL_COLUMNS, TARGET_SIZE)\n",
    "\n",
    "            if result is not None:\n",
    "                image, _ = result\n",
    "                images.append(image)\n",
    "                labels_batch.append(self.labels[i])\n",
    "            else: \n",
    "                continue\n",
    "        \n",
    "        # Convertir la lista de imágenes a un tensor (batch, 224, 224, 3)\n",
    "        X = tf.stack(images)\n",
    "        Y = tf.convert_to_tensor(labels_batch, dtype=tf.float32)\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "\n",
    "# Leer el CSV con las rutas de las imágenes y etiquetas\n",
    "df_val = pd.read_csv(CSV_PATH_TEST)\n",
    "\n",
    "# Extraer las rutas de las imágenes (asegúrate de que sean rutas absolutas o relativas correctas)\n",
    "file_paths = df_val[\"filename\"].values\n",
    "\n",
    "# Suponiendo que tus etiquetas están en las columnas \"label1\", \"label2\", \"label3\" y \"label4\"\n",
    "labels = df_val[LABEL_COLUMNS].values\n",
    "\n",
    "# Verificar las formas\n",
    "print(\"Número de muestras:\", len(file_paths))\n",
    "print(\"Shape de etiquetas:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a7b5201-6b92-46d4-8cf6-28154b52e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss...\n",
      "loss OK\n",
      "\n",
      "===== Fold 1 / 5 =====\n",
      "build_model...\n",
      "build_model OK\n",
      "compile...\n",
      "compile OK\n",
      "fit inicial...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:17,774 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:17,821 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:17,869 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:17,894 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:18,220 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:18,361 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:18,404 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:18,449 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:18,482 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:18,740 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:21,500 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:21,544 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:21,594 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:21,630 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:21,938 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:22,082 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:22,116 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:22,167 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:22,216 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:25:22,441 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 189s 3s/step - loss: 0.5914 - f1_macro: 0.7232 - f1_micro: 0.7643 - val_loss: 0.4856 - val_f1_macro: 0.8456 - val_f1_micro: 0.8717\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 176s 2s/step - loss: 0.4413 - f1_macro: 0.8055 - f1_micro: 0.8417 - val_loss: 0.4356 - val_f1_macro: 0.8470 - val_f1_micro: 0.8595\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 174s 2s/step - loss: 0.3676 - f1_macro: 0.8296 - f1_micro: 0.8626 - val_loss: 0.3467 - val_f1_macro: 0.8573 - val_f1_micro: 0.8797\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 173s 2s/step - loss: 0.3132 - f1_macro: 0.8437 - f1_micro: 0.8753 - val_loss: 0.3043 - val_f1_macro: 0.8717 - val_f1_micro: 0.8900\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 174s 2s/step - loss: 0.2689 - f1_macro: 0.8525 - f1_micro: 0.8833 - val_loss: 0.2774 - val_f1_macro: 0.8708 - val_f1_micro: 0.8812\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 174s 2s/step - loss: 0.2354 - f1_macro: 0.8543 - f1_micro: 0.8824 - val_loss: 0.2402 - val_f1_macro: 0.8682 - val_f1_micro: 0.8840\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 174s 2s/step - loss: 0.2054 - f1_macro: 0.8612 - f1_micro: 0.8857 - val_loss: 0.2310 - val_f1_macro: 0.7762 - val_f1_micro: 0.8374\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.1790 - f1_macro: 0.8717 - f1_micro: 0.8985 - val_loss: 0.1926 - val_f1_macro: 0.8460 - val_f1_micro: 0.8747\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 173s 2s/step - loss: 0.1593 - f1_macro: 0.8704 - f1_micro: 0.8972 - val_loss: 0.1899 - val_f1_macro: 0.8210 - val_f1_micro: 0.8646\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 171s 2s/step - loss: 0.1468 - f1_macro: 0.8731 - f1_micro: 0.8957 - val_loss: 0.1587 - val_f1_macro: 0.8646 - val_f1_micro: 0.8844\n",
      "fit inicial OK\n",
      "Resultados fold 1: ['loss', 'f1_macro', 'f1_micro'] = [0.15868444740772247, 0.8646053671836853, 0.8843899369239807]\n",
      "\n",
      "===== Fold 2 / 5 =====\n",
      "build_model...\n",
      "build_model OK\n",
      "compile...\n",
      "compile OK\n",
      "fit inicial...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:06,445 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:06,496 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:06,573 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:06,614 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:06,931 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:07,077 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:07,124 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:07,165 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:07,208 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:07,435 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:10,617 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:10,677 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:10,740 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:10,811 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:11,293 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:11,469 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:11,529 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:11,592 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:11,640 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 07:55:11,986 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 184s 2s/step - loss: 0.5057 - f1_macro: 0.7979 - f1_micro: 0.8305 - val_loss: 0.3379 - val_f1_macro: 0.8568 - val_f1_micro: 0.8932\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.2659 - f1_macro: 0.8417 - f1_micro: 0.8712 - val_loss: 0.2055 - val_f1_macro: 0.8669 - val_f1_micro: 0.8951\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.1822 - f1_macro: 0.8556 - f1_micro: 0.8806 - val_loss: 0.1507 - val_f1_macro: 0.8671 - val_f1_micro: 0.8963\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.1431 - f1_macro: 0.8565 - f1_micro: 0.8848 - val_loss: 0.1375 - val_f1_macro: 0.8418 - val_f1_micro: 0.8688\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.1224 - f1_macro: 0.8610 - f1_micro: 0.8866 - val_loss: 0.1116 - val_f1_macro: 0.8591 - val_f1_micro: 0.8948\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 170s 2s/step - loss: 0.1096 - f1_macro: 0.8590 - f1_micro: 0.8868 - val_loss: 0.1196 - val_f1_macro: 0.8242 - val_f1_micro: 0.8670\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 173s 2s/step - loss: 0.0988 - f1_macro: 0.8611 - f1_micro: 0.8888 - val_loss: 0.0988 - val_f1_macro: 0.8610 - val_f1_micro: 0.8891\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.0905 - f1_macro: 0.8642 - f1_micro: 0.8900 - val_loss: 0.0870 - val_f1_macro: 0.8623 - val_f1_micro: 0.8929\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.0861 - f1_macro: 0.8637 - f1_micro: 0.8923 - val_loss: 0.0852 - val_f1_macro: 0.8700 - val_f1_micro: 0.8946\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 177s 2s/step - loss: 0.0822 - f1_macro: 0.8646 - f1_micro: 0.8923 - val_loss: 0.0819 - val_f1_macro: 0.8762 - val_f1_micro: 0.8964\n",
      "fit inicial OK\n",
      "Resultados fold 2: ['loss', 'f1_macro', 'f1_micro'] = [0.08189032971858978, 0.8762494325637817, 0.8963988423347473]\n",
      "\n",
      "===== Fold 3 / 5 =====\n",
      "build_model...\n",
      "build_model OK\n",
      "compile...\n",
      "compile OK\n",
      "fit inicial...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:41,582 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:41,633 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:41,679 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:41,724 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:42,041 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:42,198 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:42,254 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:42,319 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:42,364 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:42,596 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:45,033 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:45,089 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:45,135 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:45,196 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:45,541 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:45,683 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:45,729 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:45,782 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:45,837 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:24:46,062 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 190s 3s/step - loss: 0.5139 - f1_macro: 0.7904 - f1_micro: 0.8273 - val_loss: 0.3358 - val_f1_macro: 0.8532 - val_f1_micro: 0.8841\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 174s 2s/step - loss: 0.2543 - f1_macro: 0.8323 - f1_micro: 0.8642 - val_loss: 0.2006 - val_f1_macro: 0.7873 - val_f1_micro: 0.8669\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 175s 2s/step - loss: 0.1674 - f1_macro: 0.8511 - f1_micro: 0.8785 - val_loss: 0.1441 - val_f1_macro: 0.8728 - val_f1_micro: 0.8928\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 175s 2s/step - loss: 0.1342 - f1_macro: 0.8458 - f1_micro: 0.8750 - val_loss: 0.1319 - val_f1_macro: 0.8266 - val_f1_micro: 0.8633\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 173s 2s/step - loss: 0.1131 - f1_macro: 0.8585 - f1_micro: 0.8858 - val_loss: 0.1047 - val_f1_macro: 0.8775 - val_f1_micro: 0.8989\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.1012 - f1_macro: 0.8559 - f1_micro: 0.8827 - val_loss: 0.1008 - val_f1_macro: 0.8672 - val_f1_micro: 0.8834\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 171s 2s/step - loss: 0.0921 - f1_macro: 0.8615 - f1_micro: 0.8879 - val_loss: 0.0928 - val_f1_macro: 0.8665 - val_f1_micro: 0.8881\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 171s 2s/step - loss: 0.0863 - f1_macro: 0.8676 - f1_micro: 0.8923 - val_loss: 0.0831 - val_f1_macro: 0.8777 - val_f1_micro: 0.9018\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 171s 2s/step - loss: 0.0860 - f1_macro: 0.8638 - f1_micro: 0.8900 - val_loss: 0.0854 - val_f1_macro: 0.8703 - val_f1_micro: 0.8948\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 173s 2s/step - loss: 0.0841 - f1_macro: 0.8651 - f1_micro: 0.8924 - val_loss: 0.0888 - val_f1_macro: 0.8240 - val_f1_micro: 0.8775\n",
      "fit inicial OK\n",
      "Resultados fold 3: ['loss', 'f1_macro', 'f1_micro'] = [0.0887509286403656, 0.8239853978157043, 0.8775280117988586]\n",
      "\n",
      "===== Fold 4 / 5 =====\n",
      "build_model...\n",
      "build_model OK\n",
      "compile...\n",
      "compile OK\n",
      "fit inicial...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:25,903 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:25,960 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:26,008 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:26,054 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:26,364 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:26,521 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:26,574 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:26,620 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:26,663 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:26,922 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:29,983 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:30,036 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:30,092 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:30,149 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:30,528 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:30,688 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:30,729 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:30,786 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:30,817 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 08:54:31,081 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 183s 2s/step - loss: 0.5124 - f1_macro: 0.7793 - f1_micro: 0.8241 - val_loss: 0.3402 - val_f1_macro: 0.8145 - val_f1_micro: 0.8596\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 171s 2s/step - loss: 0.2443 - f1_macro: 0.8290 - f1_micro: 0.8635 - val_loss: 0.1866 - val_f1_macro: 0.8213 - val_f1_micro: 0.8718\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 173s 2s/step - loss: 0.1577 - f1_macro: 0.8456 - f1_micro: 0.8770 - val_loss: 0.1512 - val_f1_macro: 0.7488 - val_f1_micro: 0.8562\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.1256 - f1_macro: 0.8446 - f1_micro: 0.8767 - val_loss: 0.1249 - val_f1_macro: 0.8235 - val_f1_micro: 0.8532\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.1068 - f1_macro: 0.8540 - f1_micro: 0.8849 - val_loss: 0.1092 - val_f1_macro: 0.8234 - val_f1_micro: 0.8634\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.1010 - f1_macro: 0.8569 - f1_micro: 0.8851 - val_loss: 0.1190 - val_f1_macro: 0.8522 - val_f1_micro: 0.8758\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.0946 - f1_macro: 0.8642 - f1_micro: 0.8914 - val_loss: 0.0932 - val_f1_macro: 0.8503 - val_f1_micro: 0.8853\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 184s 3s/step - loss: 0.0890 - f1_macro: 0.8555 - f1_micro: 0.8868 - val_loss: 0.0892 - val_f1_macro: 0.8577 - val_f1_micro: 0.8844\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 185s 3s/step - loss: 0.0835 - f1_macro: 0.8604 - f1_micro: 0.8907 - val_loss: 0.0894 - val_f1_macro: 0.8465 - val_f1_micro: 0.8705\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 178s 3s/step - loss: 0.0791 - f1_macro: 0.8649 - f1_micro: 0.8922 - val_loss: 0.0868 - val_f1_macro: 0.8524 - val_f1_micro: 0.8741\n",
      "fit inicial OK\n",
      "Resultados fold 4: ['loss', 'f1_macro', 'f1_micro'] = [0.08677107840776443, 0.8524383306503296, 0.8740661144256592]\n",
      "\n",
      "===== Fold 5 / 5 =====\n",
      "build_model...\n",
      "build_model OK\n",
      "compile...\n",
      "compile OK\n",
      "fit inicial...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:32,107 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:32,180 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:32,262 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:32,320 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:32,727 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:32,924 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:32,974 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:33,028 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:33,071 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:33,322 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:36,403 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:36,465 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:36,529 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:36,606 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:37,002 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:37,161 - WARNING - Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:37,233 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:37,295 - WARNING - Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:37,360 - WARNING - Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 09:24:37,702 - WARNING - Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 207s 3s/step - loss: 0.5416 - f1_macro: 0.7799 - f1_micro: 0.8197 - val_loss: 0.3456 - val_f1_macro: 0.8817 - val_f1_micro: 0.9012\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 181s 3s/step - loss: 0.2573 - f1_macro: 0.8314 - f1_micro: 0.8657 - val_loss: 0.1855 - val_f1_macro: 0.8763 - val_f1_micro: 0.9025\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 174s 2s/step - loss: 0.1656 - f1_macro: 0.8424 - f1_micro: 0.8758 - val_loss: 0.1331 - val_f1_macro: 0.8769 - val_f1_micro: 0.9003\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 174s 2s/step - loss: 0.1312 - f1_macro: 0.8416 - f1_micro: 0.8746 - val_loss: 0.1217 - val_f1_macro: 0.8802 - val_f1_micro: 0.8963\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 182s 3s/step - loss: 0.1128 - f1_macro: 0.8557 - f1_micro: 0.8829 - val_loss: 0.1102 - val_f1_macro: 0.8783 - val_f1_micro: 0.9003\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.1042 - f1_macro: 0.8379 - f1_micro: 0.8771 - val_loss: 0.0974 - val_f1_macro: 0.8766 - val_f1_micro: 0.8954\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 174s 2s/step - loss: 0.0976 - f1_macro: 0.8496 - f1_micro: 0.8793 - val_loss: 0.0906 - val_f1_macro: 0.8723 - val_f1_micro: 0.8894\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 171s 2s/step - loss: 0.0915 - f1_macro: 0.8568 - f1_micro: 0.8851 - val_loss: 0.0880 - val_f1_macro: 0.8737 - val_f1_micro: 0.8949\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 173s 2s/step - loss: 0.0873 - f1_macro: 0.8555 - f1_micro: 0.8841 - val_loss: 0.0829 - val_f1_macro: 0.8684 - val_f1_micro: 0.8957\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 171s 2s/step - loss: 0.0829 - f1_macro: 0.8632 - f1_micro: 0.8906 - val_loss: 0.0782 - val_f1_macro: 0.8789 - val_f1_micro: 0.9024\n",
      "fit inicial OK\n",
      "Resultados fold 5: ['loss', 'f1_macro', 'f1_micro'] = [0.07818916440010071, 0.8788836598396301, 0.9024258255958557]\n",
      "\n",
      "=== Resultados Promedio en K-Fold ===\n",
      "loss: 0.0989 (+/- 0.0301)\n",
      "f1_macro: 0.8592 (+/- 0.0200)\n",
      "f1_micro: 0.8870 (+/- 0.0109)\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Parámetros\n",
    "k_splits = 5\n",
    "batch_size = BATCH_SIZE\n",
    "initial_epochs = 10\n",
    "input_shape = TARGET_SIZE_CHANNEL\n",
    "num_classes = 4  # Ajusta según tu problema\n",
    "\n",
    "print('loss...')\n",
    "loss_fn = tf.keras.losses.BinaryFocalCrossentropy(gamma=2.0, alpha=alpha)\n",
    "print('loss OK')\n",
    "\n",
    "# Optimizador con learning rate adaptativo\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "num_classes = len(LABEL_COLUMNS)\n",
    "# F1-score macro promedia la F1 de cada clase.\n",
    "f1_macro = F1ScoreMacro(num_classes=num_classes, threshold=0.5)\n",
    "\n",
    "# F1-score micro calcula la F1 global (acumulando TP, FP, FN de todas las clases).\n",
    "f1_micro = F1ScoreMicro(threshold=0.5)\n",
    "\n",
    "\n",
    "# Configurar KFold\n",
    "kf = KFold(n_splits=k_splits, shuffle=True, random_state=42)\n",
    "fold_no = 1\n",
    "scores_per_fold = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(file_paths):\n",
    "    print(f'\\n===== Fold {fold_no} / {k_splits} =====')\n",
    "\n",
    "    # Dividir los datos según los índices del fold\n",
    "    train_paths, train_labels = file_paths[train_idx], labels[train_idx]\n",
    "    val_paths, val_labels = file_paths[val_idx], labels[val_idx]\n",
    "\n",
    "    # Crear generadores para entrenamiento y validación\n",
    "    train_gen = KFoldDataGenerator(train_paths, train_labels, batch_size=batch_size, shuffle=True)\n",
    "    val_gen   = KFoldDataGenerator(val_paths, val_labels, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print('build_model...')\n",
    "    model = build_model(num_classes=len(LABEL_COLUMNS))\n",
    "    print('build_model OK')\n",
    "\n",
    "    print('compile...')\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_fn,\n",
    "        metrics=[f1_macro, f1_micro]\n",
    "    )\n",
    "    print('compile OK')\n",
    "    \n",
    "    print('fit inicial...')\n",
    "    # Entrenar el modelo en el fold actual\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=initial_epochs,\n",
    "        verbose=1\n",
    "    )\n",
    "    print('fit inicial OK')\n",
    "\n",
    "    # Evaluar en el conjunto de validación del fold\n",
    "    scores = model.evaluate(val_gen, verbose=0)\n",
    "    print(f'Resultados fold {fold_no}: {model.metrics_names} = {scores}')\n",
    "    scores_per_fold.append(scores)\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Calcular el promedio y la desviación estándar de los resultados\n",
    "scores_per_fold = np.array(scores_per_fold)\n",
    "mean_scores = np.mean(scores_per_fold, axis=0)\n",
    "std_scores = np.std(scores_per_fold, axis=0)\n",
    "\n",
    "print(\"\\n=== Resultados Promedio en K-Fold ===\")\n",
    "for i, metric_name in enumerate(model.metrics_names):\n",
    "    print(f\"{metric_name}: {mean_scores[i]:.4f} (+/- {std_scores[i]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441651d-6898-48a5-9437-60d7e93b11d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fase 2: Fine-tuning\n",
    "model.summary()\n",
    "\n",
    "# Ver arquitectura detallada\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)\n",
    "\n",
    "print('Fine-tuning...')\n",
    "# 4. Fine-tuning (descongelar capas superiores)\n",
    "base_model = model.get_layer('MobilenetV3large') # Índice de la capa MobileNetV3\n",
    "base_model.trainable = True\n",
    "\n",
    "# Congelar todas las capas excepto las últimas 20\n",
    "# tomar todos los elementos de la lista excepeto los últimos 20\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "# tomar los últimos 20 elementos de la lista\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# Recompilar con learning rate más bajo\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=loss_fn,\n",
    "    metrics=[f1_macro, f1_micro]\n",
    ")\n",
    "\n",
    "# Entrenar con fine-tuning\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "print('fit...')\n",
    "history_fine = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    callbacks=[\n",
    "       tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "       tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Llamada a la función para mostrar las gráficas\n",
    "plot_training_history(history)\n",
    "print('fit OK')\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "print('save...')\n",
    "model.save(\"mobilenetv3_classifier.v.10.keras\")\n",
    "print('save OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421c7ff-b4de-45e2-9257-a2457f1b2b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('predict...')\n",
    "# Generar predicciones\n",
    "y_pred = model.predict(val_gen)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "print('predict OK')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "val_df = pd.read_csv(CSV_PATH_TEST)\n",
    "val_gen = CustomDataGenerator(val_df, BATCH_SIZE, TARGET_SIZE, LOCAL_IMAGE_PATH, label_columns=LABEL_COLUMNS, shuffle=False)\n",
    "\n",
    "# Listas para acumular predicciones y etiquetas verdaderas\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "# Iterar sobre el generador por lotes\n",
    "for i in range(len(val_gen)):\n",
    "    batch_images, batch_labels = test_gen[i]\n",
    "    batch_predictions = model.predict(batch_images, verbose=0)  # Realizar predicciones para el lote\n",
    "    \n",
    "    # Acumular predicciones y etiquetas verdaderas\n",
    "    all_predictions.append(batch_predictions)\n",
    "    all_true_labels.append(batch_labels)\n",
    "\n",
    "# Concatenar todas las predicciones y etiquetas verdaderas\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "threshold = 0.5\n",
    "predicted_labels = (all_predictions > threshold).astype(int)\n",
    "\n",
    "# Generar el informe\n",
    "report = classification_report(\n",
    "    all_true_labels,\n",
    "    predicted_labels,\n",
    "    target_names=LABEL_COLUMNS\n",
    "    output_dict=True  # Para obtener el informe como un diccionario (opcional)\n",
    ")\n",
    "\n",
    "# Imprimir el informe\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1422e50-c3fe-4fc2-b4bf-638e49e55129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "# Acumula las etiquetas verdaderas y las predicciones en listas\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "# Itera sobre el dataset de validación\n",
    "for x_batch, y_batch in val_dataset:\n",
    "    # Genera las predicciones para el batch\n",
    "    preds = model.predict(x_batch)\n",
    "    # Convierte las probabilidades a etiquetas binarias (umbral de 0.5, ajústalo si es necesario)\n",
    "    preds_binary = (preds > 0.5).astype(int)\n",
    "    \n",
    "    y_true_list.append(y_batch.numpy())\n",
    "    y_pred_list.append(preds_binary)\n",
    "\n",
    "# Concatena todos los batches en arreglos completos\n",
    "y_true = np.concatenate(y_true_list, axis=0)\n",
    "y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "\n",
    "# Calcula la matriz de confusión para cada clase\n",
    "mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Recorre y muestra la matriz de confusión de cada clase\n",
    "for i, cm in enumerate(mcm):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=[\"Pred 0\", \"Pred 1\"], \n",
    "                yticklabels=[\"True 0\", \"True 1\"])\n",
    "    plt.title(f\"Matriz de confusión para {LABEL_COLUMNS[i]}\")\n",
    "    plt.ylabel(\"Etiqueta real\")\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d7d04-b46e-4691-b2bd-8eb54c00db14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
