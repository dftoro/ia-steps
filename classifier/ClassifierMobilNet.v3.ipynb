{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da34c733-2eec-4bc8-b968-017b72c0bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e56ea53-0899-4210-ba5a-f61da993326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(row, local_path_dataset, target_size):\n",
    "    \"\"\"\n",
    "    Cargar una imagen la cual puede estar local o remotar en una url\n",
    "    Argments\n",
    "        row:                 Registro panda con la información de un ejemplo de entrada: la imagen puede estar local o remota (urlAbsoluta)\n",
    "        local_path_dataset:  Ruta local donde se encuentran las imágens\n",
    "        target_size:         Tamñao de la imagen de salia una vez cargada\n",
    "    Returns\n",
    "        Imagen redimensionada y como un arreglo\n",
    "    \"\"\"\n",
    "    #Cargar el csv para encontrar el nombre o Url de los archivos a cargas\n",
    "    try:\n",
    "        if pd.notna(row['urlAbsoluta']):\n",
    "            # Descargar la imagen desde la URL\n",
    "            response = requests.get(row['urlAbsoluta'], timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                image = load_img(BytesIO(response.content), target_size=target_size)\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            # Cargar la imagen localmente\n",
    "            # ajuste según dataset local\n",
    "            filename = row['filename']\n",
    "            prefix = 'no_dogs' if \"nodogs\" in filename else 'dogs'\n",
    "            directory = os.path.join(local_path_dataset, prefix)\n",
    "            local_path = os.path.join(directory, filename)\n",
    "            if os.path.exists(local_path):\n",
    "                image = load_img(local_path, target_size=target_size)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "            \n",
    "        return img_to_array(image) / 255.0  # Escalar al rango [0, 1]\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error al descargar la imagen {row['urlAbsoluta']}: {e}\")\n",
    "            return None    \n",
    "    except FileNotFoundError:\n",
    "            print(f\"Archivo no encontrado: {row['filename']}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "            print(f\"Error al abrir la imagen {row['filename']}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb388c89-ea9c-4c69-93d7-1d55b19df2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(row):\n",
    "    \"\"\"\n",
    "    Procesar las etiquetas como un vector binario\n",
    "    Argments\n",
    "        row:                 Registro panda con la información de un ejemplo de entrada: la imagen puede estar local o remota (urlAbsoluta)\n",
    "    Returns\n",
    "        arreglo binario con las etiqutas\n",
    "    \"\"\"\n",
    "    #return [row['direccion'], row['fachada'], row['envio'], row['etiqueta']]\n",
    "    return [row['perro'], row['gato']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f772cc2-1489-4601-bad5-ac024e3d37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(row, local_path_dataset, target_size): \n",
    "    \"\"\"\n",
    "    Prepare los datos basado en el registro del archivo csv de entrada\n",
    "    Arguments\n",
    "        row:                 Registro panda con la información de un ejemplo de entrada: la imagen puede estar local o remota (urlAbsoluta)\n",
    "        local_path_dataset:  Ruta local donde se encuentran las imágens\n",
    "        target_size:         Tamñao de la imagen de salia una vez cargada\n",
    "    Returns \n",
    "        [arreglo con las imagenes, arreglo con los labels]\n",
    "    \"\"\"\n",
    "     # Preparar las etiquetas\n",
    "    labels = preprocess_labels(row)\n",
    "    img_array = load_image(row, local_path_dataset, target_size)\n",
    "\n",
    "    return img_array, np.array(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61478e6-c2ab-4f2a-a91a-03bf497d33f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_data(csv_path, local_path_dataset, target_size, max_workers=4):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Inicializar array para almacenar imágenes\n",
    "    images = []\n",
    "    # Inicializar array para almacenar labels\n",
    "    labels = []\n",
    "\n",
    "    label_columns = ['perro', 'gato']\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "         # Procesar cada fila del DataFrame\n",
    "         futures = [executor.submit(prepare_input, row, local_path_dataset, target_size) \n",
    "                    for _, row in df.iterrows()]\n",
    "         \n",
    "         for future in tqdm(futures, total=len(df)):\n",
    "             result = future.result()\n",
    "             if result is not None:\n",
    "                 img_array, img_labels = result\n",
    "\n",
    "                 if img_array is not None and img_array.shape == (224, 224, 3):  # Verificar forma\n",
    "                     images.append(img_array)\n",
    "                     labels.append(img_labels)\n",
    "                 else:\n",
    "                      print(f\"Imagen inválida o con tamaño incorrecto\")\n",
    "\n",
    "    X = np.array(images)\n",
    "    y = np.array(labels)\n",
    "        \n",
    "    print(f\"\\nDataset preparado con {len(X)} imágenes\")\n",
    "    print(f\"Distribución de clases:\")\n",
    "    for i, col in enumerate(label_columns):\n",
    "        positive_samples = np.sum(y[:, i])\n",
    "        percentage = (positive_samples / len(y)) * 100\n",
    "        print(f\"{col}: {percentage:.2f}% ({int(positive_samples)}/{len(y)})\")\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979853d8-93a2-4831-b7bd-3a7c2c264a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_smote(X, y, k_neighbors=5):\n",
    "    \"\"\"\n",
    "    Aplica SMOTE a un dataset multi-label.\n",
    "    Genera datos sintéticos basados en las combinaciones de etiquetas.\n",
    "    \"\"\"\n",
    "    # Combinar etiquetas multi-label en cadenas únicas para identificarlas\n",
    "    label_combinations = [''.join(map(str, labels)) for labels in y]\n",
    "    \n",
    "    # Convertir etiquetas en índices únicos\n",
    "    unique_combinations, y_indices = np.unique(label_combinations, return_inverse=True)\n",
    "    \n",
    "    # Aplicar SMOTE sobre las combinaciones\n",
    "    smote = SMOTE(k_neighbors=k_neighbors)\n",
    "    \n",
    "    # Aplanar las imágenes a vectores unidimensionales\n",
    "    X_flattened = X.reshape(len(X), -1)\n",
    "    X_resampled_flattened, y_resampled_indices = smote.fit_resample(X_flattened, y_indices)\n",
    "\n",
    "    # Restaurar la forma original de las imágenes\n",
    "    X_resampled = X_resampled_flattened.reshape(-1, 224, 224, 3)\n",
    "    \n",
    "    # Convertir los índices resampleados de nuevo a multi-label\n",
    "    y_resampled = np.array([list(map(int, comb)) for comb in unique_combinations[y_resampled_indices]])\n",
    "    \n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9105f1e3-9ed7-4526-936a-40d7edbf616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular factores de aumentación\n",
    "def calculate_augmentation_factors(labels, target_balance=0.25):\n",
    "    num_samples = len(labels)\n",
    "    label_counts = np.sum(labels, axis=0)\n",
    "    max_samples = target_balance * num_samples\n",
    "    augmentation_factors = {i: int(np.ceil(max_samples / count)) if count > 0 else 1\n",
    "                             for i, count in enumerate(label_counts)}\n",
    "    return augmentation_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0ef976-10af-4161-bed3-b2e770e55edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_batch_generator_with_smote(X, y, batch_size, smote_frequency=10, k_neighbors=5):\n",
    "    \"\"\"\n",
    "    Generador de datos balanceados usando la técnica de SMOTE\n",
    "\n",
    "\n",
    "    Returns\n",
    "        X,y conjuntos balanceados para hacer el entrenamiento\n",
    "    \"\"\"\n",
    "    # Dividir los índices de las clases\n",
    "    from collections import defaultdict\n",
    "    class_indices = defaultdict(list)\n",
    "\n",
    "    for i, labels in enumerate(y):\n",
    "        for cls, label in enumerate(labels):\n",
    "            if label == 1:  # Etiqueta positiva\n",
    "                class_indices[cls].append(i)\n",
    "\n",
    "    label_columns = ['perro', 'gato']\n",
    "    n_classes = y.shape[1]\n",
    "    counter = 0  # Para rastrear cuándo aplicar SMOTE\n",
    "\n",
    "    # Crear un batch balanceado\n",
    "    while True:\n",
    "        batch_X, batch_y = [], []\n",
    "\n",
    "        # Aplicar SMOTE cada cierto número de batches\n",
    "        if counter % smote_frequency == 0:\n",
    "            X, y = multi_label_smote(X, y, k_neighbors=k_neighbors)\n",
    "\n",
    "        # Crear un batch balanceado\n",
    "        for _ in range(batch_size):\n",
    "            # Seleccionar aleatoriamente una clase\n",
    "            cls = np.random.choice(n_classes)\n",
    "            \n",
    "            # Obtener índices aleatorios de esa clase\n",
    "            sample_idx = np.random.choice(class_indices[cls])\n",
    "\n",
    "            # Agregar al batch\n",
    "            batch_X.append(X[sample_idx])\n",
    "            batch_y.append(y[sample_idx])\n",
    "\n",
    "        counter += 1\n",
    "        X_array = np.array(batch_X)\n",
    "        y_array = np.array(batch_y)\n",
    "\n",
    "        print(f\"\\nDataset preparado con {len(X_array)} imágenes\")\n",
    "        print(f\"Distribución de clases:\")\n",
    "        for i, col in enumerate(label_columns):\n",
    "            positive_samples = np.sum(y_array[:, i])\n",
    "            percentage = (positive_samples / len(y_array)) * 100\n",
    "            print(counter)\n",
    "            print(f\"{col}: {percentage:.2f}% ({int(positive_samples)}/{len(y_array)})\")\n",
    "            \n",
    "        yield X_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb94272b-1c69-49b3-836a-fe0fc7448d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(target_size, output_units=2):\n",
    "    # Carga del modelo base\n",
    "    base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=target_size)\n",
    "\n",
    "    # Congela capas iniciales\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Agrega capas personalizadas\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(output_units, activation='sigmoid')  # Activación para multi-label\n",
    "    ])\n",
    "\n",
    "    # Compila el modelo\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', AUC(name='auc')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a3ed78-785f-48e2-8c94-bede35f6e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumentación adaptativa\n",
    "def augment_images_adaptive(X, y, augmentation_factors, datagen):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        image = X[i]\n",
    "        label = y[i]\n",
    "        max_factor = max([augmentation_factors[j] for j, present in enumerate(label) if present])\n",
    "\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        augmented_iter = datagen.flow(image, batch_size=1)\n",
    "        \n",
    "        for _ in range(max_factor):\n",
    "            augmented_images.append(next(augmented_iter)[0])\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "    return np.array(augmented_images), np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ae1535-8e6b-4562-8694-3fa4a576a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceo con SMOTE\n",
    "def balance_with_smote(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_flattened = X.reshape(len(X), -1)\n",
    "    y_encoded = encode_multilabel(y)\n",
    "    X_resampled_flattened, y_resampled_encoded = smote.fit_resample(X_flattened, y_encoded)\n",
    "    X_resampled = X_resampled_flattened.reshape(-1, 224, 224, 3)\n",
    "    y_resampled = decode_multilabel(y_resampled_encoded)\n",
    "    \n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb519cb3-2d5f-4fba-a6f6-768913d77411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_multilabel(encoded_labels, num_classes=4):\n",
    "    return np.array([[int(char) for char in label] for label in encoded_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f3c2f4b-fde0-4f78-914b-8a49fb05be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir etiquetas multietiqueta\n",
    "def encode_multilabel(labels):\n",
    "    return np.array([\"\".join(map(str, label)) for label in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b73dc862-8ede-4067-9e9b-09d3eb6c875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(images, labels, title, num_images=5):\n",
    "    \"\"\"\n",
    "    Muestra un conjunto de imágenes con sus etiquetas asociadas.\n",
    "    \n",
    "    Args:\n",
    "        images (np.array): Arreglo de imágenes (formato HWC, RGB).\n",
    "        labels (np.array): Etiquetas asociadas a las imágenes.\n",
    "        title (str): Título de la visualización.\n",
    "        num_images (int): Número de imágenes a mostrar.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(min(num_images, len(images))):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        img = images[i]\n",
    "        \n",
    "        # Asegurar que la imagen esté en el rango [0, 255]\n",
    "        if img.max() <= 1.0:\n",
    "            img = img * 255.0\n",
    "        img = img.astype(\"uint8\")\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Etiqueta: {labels[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339a59f6-abe5-4a69-be19-86b5ae293d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Muestra los gráficos de pérdida y precisión durante el entrenamiento.\n",
    "    \n",
    "    Args:\n",
    "        history (History): Objeto de historial devuelto por model.fit().\n",
    "    \"\"\"\n",
    "    # Extraer métricas\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    accuracy = history.history.get('accuracy', [])\n",
    "    val_accuracy = history.history.get('val_accuracy', [])\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # Gráfico de pérdida\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'bo-', label='Pérdida Entrenamiento')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Pérdida Validación')\n",
    "    plt.title('Pérdida durante el Entrenamiento')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "\n",
    "    # Gráfico de precisión (si está disponible)\n",
    "    if accuracy:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, accuracy, 'bo-', label='Precisión Entrenamiento')\n",
    "        plt.plot(epochs, val_accuracy, 'ro-', label='Precisión Validación')\n",
    "        plt.title('Precisión durante el Entrenamiento')\n",
    "        plt.xlabel('Épocas')\n",
    "        plt.ylabel('Precisión')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd619739-7ab1-482d-b22d-a7022cc70b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                | 4/24999 [00:00<07:43, 53.93it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dogs-no-dogs.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minicio\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m X, y \u001b[38;5;241m=\u001b[39m read_input_data(csv_path, local_path_dataset\u001b[38;5;241m=\u001b[39mDATASET_PATH, target_size\u001b[38;5;241m=\u001b[39mIMG_SIZE, max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_input_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX=\u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m, in \u001b[0;36mread_input_data\u001b[1;34m(csv_path, local_path_dataset, target_size, max_workers)\u001b[0m\n\u001b[0;32m     23\u001b[0m                  labels\u001b[38;5;241m.\u001b[39mappend(img_labels)\n\u001b[0;32m     24\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m                   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImagen inválida o con tamaño incorrecto: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(images)\n\u001b[0;32m     28\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "INPUT_SIZE = (224, 224, 3)\n",
    "BATCH_SIZE = 8\n",
    "DATASET_PATH = \"../DataSets/cats_vs_dogs/\"\n",
    "\n",
    "csv_path = './dogs-no-dogs.csv'\n",
    "\n",
    "print('inicio')\n",
    "X, y = read_input_data(csv_path, local_path_dataset=DATASET_PATH, target_size=IMG_SIZE, max_workers=4)\n",
    "print('read_input_data')\n",
    "print('X=', X.shape)\n",
    "print('y=', y.shape)\n",
    "\n",
    "np.savez_compressed('X_y', X=X, y=y)\n",
    "print('savez_compressed')\n",
    "\n",
    "#loaded = np.load('X_y.npz')\n",
    "#X = loaded['X']\n",
    "#y = loaded['y']\n",
    "#print('X=', X.shape)\n",
    "#print('y=', y.shape)\n",
    "\n",
    "# Configuración de Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Cargar datos (se supone que tienes las variables `images` y `labels`)\n",
    "# Divide en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('train_test_split')\n",
    "del X\n",
    "del y\n",
    "gc.collect()\n",
    "visualize_images(X_train[:5], y_train[:5], \"Imágenes Originales\")\n",
    "\n",
    "# Aumentación adaptativa\n",
    "augmentation_factors = calculate_augmentation_factors(y_train, target_balance=0.25)\n",
    "print('calculate_augmentation_factors')\n",
    "X_train_augmented, y_train_augmented = augment_images_adaptive(X_train, y_train, augmentation_factors, datagen)\n",
    "visualize_images(X_train_augmented[:5], y_train_augmented[:5], \"Imágenes Después de Aumentación\")\n",
    "\n",
    "print('augment_images_adaptive')\n",
    "print(\"Distribución después de aumentación:\", Counter(encode_multilabel(y_train_augmented)))\n",
    "\n",
    "del X_train\n",
    "del y_train\n",
    "gc.collect()\n",
    "\n",
    "# Aplicar SMOTE\n",
    "X_train_balanced, y_train_balanced = balance_with_smote(X_train_augmented, y_train_augmented)\n",
    "visualize_images(X_train_balanced[:5], y_train_balanced[:5], \"Imágenes Después de SMOTE\")\n",
    "\n",
    "print('balance_with_smote')\n",
    "print(\"Distribución después de SMOTE:\", Counter(encode_multilabel(y_train_balanced)))\n",
    "\n",
    "del X_train_augmented\n",
    "del y_train_augmented\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model = build_model(target_size=INPUT_SIZE, output_units=2)\n",
    "print('build_model')\n",
    "\n",
    "\n",
    "# Checkpoint para guardar el mejor modelo\n",
    "checkpoint = ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(\n",
    "    X_train_balanced, y_train_balanced,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "# Entrenar el modelo\n",
    "#model.fit(generator, steps_per_epoch=len(X) // BATCH_SIZE, epochs=20)\n",
    "print('fit')\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save(\"dog_nodogs_balanced.keras\", save_format=\"keras\")\n",
    "\n",
    "# Visualizar el historial de entrenamiento\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0915f3-100b-402c-a834-86d34cdfd47b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
