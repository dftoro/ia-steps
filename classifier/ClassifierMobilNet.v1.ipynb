{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49391a7a-7114-45e4-a634-af148ee4a3be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del DataFrame: 25000\n",
      "train_df= 20000  val_df= 5000\n",
      "len(indices) 16\n",
      "10773.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/dogs --> 10773.jpg\n",
      "Error: Índice 20417 fuera de los límites. Longitud del DataFrame: 20000\n",
      "4246.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/dogs --> 4246.jpg\n",
      "661_nodogs.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/no_dogs --> 661_nodogs.jpg\n",
      "10144.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/dogs --> 10144.jpg\n",
      "1080.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/dogs --> 1080.jpg\n",
      "Error: Índice 23770 fuera de los límites. Longitud del DataFrame: 20000\n",
      "Error: Índice 20334 fuera de los límites. Longitud del DataFrame: 20000\n",
      "4739_nodogs.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/no_dogs --> 4739_nodogs.jpg\n",
      "11558.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/dogs --> 11558.jpg\n",
      "6135_nodogs.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/no_dogs --> 6135_nodogs.jpg\n",
      "6140_nodogs.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/no_dogs --> 6140_nodogs.jpg\n",
      "6549_nodogs.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/no_dogs --> 6549_nodogs.jpg\n",
      "6083.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/dogs --> 6083.jpg\n",
      "7643.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/dogs --> 7643.jpg\n",
      "4131_nodogs.jpg nan nan\n",
      "../DataSets/cats_vs_dogs/no_dogs --> 4131_nodogs.jpg\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NumpyArrayIterator' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 144\u001b[0m\n\u001b[0;32m    141\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mbase_model\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39mpredictions)\n\u001b[0;32m    142\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinaryCrossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 144\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    145\u001b[0m     train_generator,\n\u001b[0;32m    146\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39mtrain_len\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m BATCH_SIZE, \u001b[38;5;66;03m#Se multiplica por dos el total de datos porque se duplican en cada batch\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m    148\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m    149\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mval_len \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m BATCH_SIZE\n\u001b[0;32m    150\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifier\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[29], line 117\u001b[0m, in \u001b[0;36mpreparar_datos.<locals>.balanced_batch_generator_smote\u001b[1;34m(df, datagen, batch_size, etiquetas_unicas)\u001b[0m\n\u001b[0;32m    114\u001b[0m     image_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((image_batch, image_batch_resampled))\n\u001b[0;32m    115\u001b[0m     label_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((label_batch, label_batch_resampled))\n\u001b[1;32m--> 117\u001b[0m image_batch \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow(image_batch, batch_size\u001b[38;5;241m=\u001b[39mbatch_size\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mnext()\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m image_batch, label_batch\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NumpyArrayIterator' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import requests\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import math\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "DATASET_PATH = \"../DataSets/cats_vs_dogs/\"\n",
    "\n",
    "def cargar_imagen(row):\n",
    "    \"\"\"Carga una imagen desde un archivo local o una URL.\"\"\"\n",
    "    print(row['filename'], row['urlAbsoluta'], row['urlAbsoluta'].astype(str).strip()) \n",
    "    if len(row['urlAbsoluta'].astype(str).strip()) > 0 and not math.isnan(row['urlAbsoluta']):\n",
    "        try:\n",
    "            response = requests.get(row['urlAbsoluta'], stream=True, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error al descargar la imagen {row['urlAbsoluta']}: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error al abrir la imagen descargada {row['urlAbsoluta']}: {e}\")\n",
    "            return None\n",
    "    elif row['filename']:\n",
    "        prefix = ''\n",
    "        if \"nodogs\" in row['filename']:\n",
    "            prefix = 'no_dogs'\n",
    "        else:\n",
    "            prefix = 'dogs'\n",
    "\n",
    "        directory = os.path.join(DATASET_PATH, prefix)\n",
    "        print(directory, '-->', row['filename']) \n",
    "        filepath = os.path.join(directory, row['filename'])\n",
    "        try:\n",
    "            img = Image.open(filepath).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Archivo no encontrado: {filepath}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error al abrir la imagen {filepath}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Ni urlAbsoluta ni filename proporcionados.\")\n",
    "        return None\n",
    "    return img.resize(IMG_SIZE)\n",
    "\n",
    "def preparar_datos(csv_path):\n",
    "    \"\"\"Prepara los datos para el entrenamiento.\"\"\"\n",
    "    chunksize = 1000  # Leer 1000 filas a la vez\n",
    "    chunks = []\n",
    "    #df = pd.read_csv(csv_path)\n",
    "    for chunk in pd.read_csv(csv_path, chunksize=chunksize):\n",
    "        chunks.append(chunk)\n",
    "    df = pd.concat(chunks)\n",
    "    print(f\"Longitud del DataFrame: {len(df)}\")\n",
    "    \n",
    "    # Usar las columnas 'perro' y 'gato' como etiquetas\n",
    "    etiquetas_unicas = ['perro', 'gato']  # Definir las etiquetas directamente\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print('train_df=',len(train_df), ' val_df=',len(val_df))\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    def balanced_batch_generator_smote(df, datagen, batch_size, etiquetas_unicas):\n",
    "        \"\"\"Genera batches balanceados con SMOTE para clasificación multi-label.\"\"\"\n",
    "        smote = SMOTE(random_state=42)\n",
    "        while True:\n",
    "            image_batch = []\n",
    "            label_batch = []\n",
    "            indices = np.random.choice(df.index, size=batch_size, replace=False)\n",
    "            print('len(indices)', len(indices))\n",
    "            for index in indices:\n",
    "                if index >= len(df):  # Verificar si el índice está fuera de los límites\n",
    "                    print(f\"Error: Índice {index} fuera de los límites. Longitud del DataFrame: {len(df)}\")\n",
    "                    continue  # Saltar a la siguiente iteración\n",
    "                row = df.iloc[index]\n",
    "                img = cargar_imagen(row)\n",
    "                if img is not None:\n",
    "                    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                    image_batch.append(img_array)\n",
    "                    labels = row[etiquetas_unicas].values.astype(np.float32)\n",
    "                    label_batch.append(labels)\n",
    "            image_batch = np.array(image_batch)\n",
    "            label_batch = np.array(label_batch)\n",
    "\n",
    "            # Aplicar SMOTE a cada etiqueta por separado\n",
    "            original_shape = image_batch.shape\n",
    "            if image_batch.shape[0] > 0: #Verificar que el batch tenga datos antes de aplicar smote\n",
    "                for i in range(label_batch.shape[1]):\n",
    "                    X_resampled, y_resampled = smote.fit_resample(image_batch.reshape(image_batch.shape[0], -1), label_batch[:, i])\n",
    "                    if i == 0:\n",
    "                        X_resampled_all = X_resampled\n",
    "                        y_resampled_all = y_resampled.reshape(-1,1)\n",
    "                    else:\n",
    "                        y_resampled_all = np.concatenate((y_resampled_all, y_resampled.reshape(-1,1)), axis = 1)\n",
    "                \n",
    "                image_batch_resampled = X_resampled_all.reshape(-1, IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "                label_batch_resampled = y_resampled_all\n",
    "                image_batch = np.concatenate((image_batch, image_batch_resampled))\n",
    "                label_batch = np.concatenate((label_batch, label_batch_resampled))\n",
    "            \n",
    "            image_batch = datagen.flow(image_batch, batch_size=batch_size*2 if original_shape[0] > 0 else batch_size, shuffle=True).next()\n",
    "            yield image_batch, label_batch\n",
    "\n",
    "    train_generator = balanced_batch_generator_smote(train_df, datagen, BATCH_SIZE, etiquetas_unicas)\n",
    "    validation_generator = balanced_batch_generator_smote(val_df, datagen, BATCH_SIZE, etiquetas_unicas) #No aplicar smote en validacion\n",
    "\n",
    "    return train_generator, validation_generator, etiquetas_unicas, len(train_df), len(val_df)\n",
    "\n",
    "# Ejemplo de uso:\n",
    "csv_file = './dogs-no-dogs.csv'\n",
    "train_generator, validation_generator, etiquetas_unicas, train_len, val_len = preparar_datos(csv_file)\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(len(etiquetas_unicas), activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='BinaryCrossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_len*2 // BATCH_SIZE, #Se multiplica por dos el total de datos porque se duplican en cada batch\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_len // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8607f1-d767-4e4b-8ee4-1fbc5478151f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
